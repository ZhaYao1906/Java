# 并发

- 什么是并发安全问题？（偏基础概念）

并发安全问题是指在多线程或多进程的环境中，**多个线程或进程同时访问和修改共享资源时**，可能**导致数据不一致、竞态条件、死锁**等错误状态。这些问题通常发生在没有适当的同步机制或管理机制来控制并发访问的情况下。

# 1 线程

## 1.1 线程与进程

进程是程序的一次执行过程，是系统运行程序的基本单位。在Java中，当我们启动main函数时其实就是启动了一个JVM的进程，**而main函数所在的线程就是这个进程中的一个线程，也称为主线程。**

## 1. 2 Java线程和操作系统的线程有啥区别？

**现在的Java线程本质就是操作系统的线程**

- 用户线程：由用户空间程序管理和调度的线程，运行在用户空间（专门给应用程序使用）。
- 内核线程：由操作系统内核管理和调度的线程，运行在内核空间（只有内核程序可以访问）。

**JDK1.2之前，Java线程是一种用户级线程，JDK1.2以后，JVM直接使用操作系统原生的内核级线程（内核线程）来实现Java线程。**

## 1.3 Java中如何创建线程？

**1、继承`Thread`类**

```java
class MyThread extends Thread {
    @Override
    public void run() {
        for (int i = 0; i < 5; i++) {
            System.out.println(Thread.currentThread().getName() + " - Count: " + i);
        }
    }
}

public class ThreadExample {
    public static void main(String[] args) {
        MyThread thread1 = new MyThread();
        MyThread thread2 = new MyThread();

        thread1.start(); // 启动线程1
        thread2.start(); // 启动线程2
    }
}
```

**2、实现`Runnable`接口**

```java
class MyRunnable implements Runnable {
    @Override
    public void run() {
        for (int i = 0; i < 5; i++) {
            System.out.println(Thread.currentThread().getName() + " - Count: " + i);
        }
    }
}

public class RunnableExample {
    public static void main(String[] args) {
        MyRunnable myRunnable = new MyRunnable();
        Thread thread1 = new Thread(myRunnable);
        Thread thread2 = new Thread(myRunnable);

        thread1.start(); // 启动线程1
        thread2.start(); // 启动线程2
    }
}
```

**3、实现`Callable`接口**

Callable的call()方法可以有返回值并且可以抛出异常。

```java
class MyCallable implements Callable<Integer> {
    @Override
    public Integer call() throws Exception {
        int count = 0;
        for (int i = 0; i < 5; i++) {
            count++;
            System.out.println(Thread.currentThread().getName() + " - Count: " + count);
        }
        return count; // 返回值
    }
}

public class CallableExample {
    public static void main(String[] args) {
        ExecutorService executor = Executors.newFixedThreadPool(2);
        Future<Integer> future1 = executor.submit(new MyCallable());
        Future<Integer> future2 = executor.submit(new MyCallable());

        try {
            System.out.println("Future1 Result: " + future1.get()); // 获取结果
            System.out.println("Future2 Result: " + future2.get()); // 获取结果
        } catch (InterruptedException | ExecutionException e) {
            e.printStackTrace();
        } finally {
            executor.shutdown(); // 关闭线程池
        }
    }
}
```

4（相当于补充） 使用线程池（Executor框架）

```java
class Task implements Runable{
			@Override
			public void run(){
					//线程执行的代码
			}
}

public static void main(String[] args){
		ExecutorService executor = Executors.newFixedThreadPool(10); //创建固定大小的线程池
		for(int i = 0;i < 100;i++){
				executor.submit(new Task()); //提交任务到线程池执行	
		}
		executor.shutdown(); //关闭线程池
}
```

## 1.4 线程的生命周期和状态

Java线程在运行的生命周期中的指定时刻只可能处于下面6种不同状态的其中一个状态：

- **NEW 初始状态：**线程被创建出来但没有被调用 start() 。
- **RUNNABLE 运行状态：**线程被调用了 start()等待运行的状态。
- **BLOCKED 阻塞状态：**需要等待锁释放。
- **WAITING 等待状态：**表示该线程需要等待其他线程做出一些特定动作（通知或中断）。
- **TIME_WAITING 超时等待状态：**可以在指定的时间后自行返回而不是像 WAITING 那样一直等待。
- **TERMINATED 终止状态：**表示该线程已经运行完毕。

![image.png](%E5%B9%B6%E5%8F%91%20137aa808854d49ceab1550336a1e46f2/image.png)

## 1.5 什么是线程上下文切换

线程在执行过程中会有自己的**运行条件和状态（也称上下文）：程序计数器、栈信息**

线程切换意味着需要保存当前线程的上下文，留待线程下次占用CPU的时候恢复现场。并加载下一个将要占用CPU的线程上下文。这就是所谓的 **上下文切换。**

**发生上下文切换的场景：**

- 主动让出 CPU，比如调用了 `sleep()`, `wait()` 等。
- 时间片用完，因为操作系统要防止一个线程或者进程长时间占用 CPU 导致其他线程或者进程饿死。
- 调用了阻塞类型的系统中断，比如请求 IO，线程被阻塞。

## 1.6 Thread#Sleep()与Object#wait()

### 定义

`Thread.sleep(long millis)` 是一个静态方法，用于让当前执行的线程休眠指定的毫秒数。调用 `sleep()` 方法会让线程进入 `TIMED_WAITING` 状态，直到指定的时间过去。

### sleep与wait区别

- `sleep()` 方法只影响当前线程。**不会释放资源。**适用于在某个线程中**暂停执行一段时间。**
- wait() 是 Object 类的方法。它使调用对象的线程进入等待状态，**直到另一个线程调用同一对象的notify()的或 notifyAll() 方法。会释放资源。**适用于**线程间的通信。**

### **为什么wait方法定义在Object类中？**

**wait() 是让获得对象锁的线程实现等待，会自动释放当前线程占有的对象锁。**每个对象（Object）都拥有对象锁，既然要释放当前线程占有的对象锁并让其进入 WAITING 状态，自然是要操作对应的对象（Object）而非当前的线程（Thread）。

### **为什么sleep()方法定义在Thread中？**

因为 sleep() 是**让当前线程暂停执行**，不涉及到对象类，也不需要获得对象锁。

## 1.7 可以直接调用Thread类的run方法吗？

new 一个 `Thread`，线程进入了新建状态。调用 `start()`方法，会启动一个线程并使线程进入了就绪状态，当分配到时间片后就可以开始运行了。`start()` 会执行线程的相应准备工作，然后自动执行 `run()` 方法的内容，这是真正的多线程工作。

但是，直接执行 `run()` 方法，会把 `run()` 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。
**总结：调用 `start()` 方法方可启动线程并使线程进入就绪状态，直接执行 `run()` 方法的话不会以多线程的方式执行。**

## **1.8 如何停止一个线程的运行？**

- **使用标志位控制线程退出**

Java中可以设置一个标志位来控制线程的运行和退出，线程在运行时定期检查这个标志位，如果标志位指示线程应该停止，线程就会自行退出。

- **使用 Thread.interrupt() 中断线程**

Java提供了Thread.interrupt() 方法来中断线程。线程可以通过检查 Thread.isInterrupted() 或捕获 InterruptedException 来响应中断请求。

- **Thread.stop()暴力停止**

Thread.stop() 方法可以强制停止线程，但它是 **不安全的**，因为它会**立即终止线程，可能导致资源未释放、数据不一致等问题。**

- **使用 ExecutorService 管理线程**

如果使用线程池（ExecutorService），可以通过 **shutdown() 或 shutdownNow()** 来停止线程池中的线程。

### **调用 interrupt 是如何让线程抛出异常的？（重点）**

在Java中，调用 Thread.interrupt() 并不会直接让线程抛出异常，而是**会设置线程的中断状态（interrupt status）**。**每一个线程都有与之关联的布尔属性来表示其中断状态**，中断状态的初始值为false。**当一个线程被其它线程调用 Thread.interrupt()方法中断时，会根据实际情况做出响应。**

**Step1 :设置中断状态：**调用 Thread.interrupt() 会将线程的中断状态设置为 true 。

**Step2:线程的响应方式：**线程是否抛出异常取决于线程的当前状态和代码的实现方式 ：

**1、线程处于阻塞状态：如果该线程正在执行低级别的可中断方法**（如Thread.sleep()、Thread.join()或Object.wait()）,则会**解除阻塞并抛出InterruptedException异常。**

**2、线程处于运行状态：如果线程正在运行（没有阻塞），调用 interrupt() 不会直接抛出异常，但可以通过检查中断状态来响应中断请求。**

# 2 多线程

## 2.1 基本概念

**并发与并行的区别：**

- **并发**：两个及两个以上的作业在同一 **时间段** 内执行。
- **并行**：两个及两个以上的作业在同一 **时刻** 执行。

**同步和异步的区别：**

- **同步**：发出一个调用之后，在没有得到结果之前， 该调用就不可以返回，一直等待。
- **异步**：调用在发出之后，不用等待返回结果，该调用直接返回。

## 2.2 单核CPU支持Java多线程吗？

**单核CPU是支持Java多线程的。**

操作系统通过时间片轮转的方式，将CPU时间分配给不同的线程。尽管单核CPU一次只能执行一个任务，但通过快速在多个线程之间切换，可以让用户感觉多个任务是同时进行的。

## 2.3 死锁

线程死锁：多个线程同时被阻塞，它们中的一个或者全部都在等待某个资源被释放。由于线程被无限期地阻塞，因此程序不可能正常终止。

- **如何检测死锁？**

方法1：使用jmap、jstack 等命令查看 JVM 线程栈和堆内存的情况。如果有死锁，jstack 的输出中通常会有 Found one Java-level deadlock:的字样，后面会跟着死锁相关的线程信息。

方法2：采用 VisualVM、JConsole 等工具进行排查。

## 2.4 Java中有哪些同步方式？

**1、`synchronized` 关键字**

在方法声明或代码块上使用 `synchronized` 关键字，保证同一时间只有一个线程可以执行被同步的方法或代码块。

**2、`ReentrantLock`** 

`ReentrantLock` 是一个显式锁，它提供了更灵活的锁机制，**（使用Condition对象来提供更灵活的等待、通知机制）**可以替代 `synchronized` 关键字。

**支持公平锁和非公平锁**，支持多种锁的尝试、定时锁等待和可中断锁等待。

**3、`Atomic` 变量**

- Java 提供了 `java.util.concurrent.atomic` 包，其中包含了各种原子变量，如 `AtomicInteger`、`AtomicLong`、`AtomicReference` 等。
- 原子变量通过 CAS（Compare-And-Swap）操作实现无锁的线程安全。

**4、`Exchanger`** 

`Exchanger` 是 Java 并发包中的一个同步工具，主要用于线程之间的数据交换。它允许**两个线程在某个点相遇并交换信息。**

**用途**：主要用于线程协作和数据交换的场景，比如在并行计算中，两个线程需要交换数据才能继续工作。

**机制**：通过`exchange`方法实现线程间的数据交换，线程会在`exchange`调用处被阻塞，直到另一个线程也调用`exchange`。

# 3 JMM（Java内存模型）

JMM(Java 内存模型)主要定义了对于一个 共享变量，当另一个线程对这个 **共享变量 执行写操作**后，这个线程对这个共享变量 具有 可见性。

## **3.1 CPU缓存模型**

**CPU 缓存则是为了解决 CPU 处理速度和内存处理速度不对等的问题。**

我们可以把 **内存看作外存的高速缓存**，程序运行的时候我们把外存的数据复制到内存，由于内存的处理速度远远高于外存，这样提高了处理速度。

总结：**CPU Cache 缓存的是内存数据用于解决 CPU 处理速度和内存不匹配的问题，内存缓存的是硬盘数据用于解决硬盘访问速度过慢的问题。**

**操作系统通过 内存模型（Memory Model） 定义一系列规范来解决内存缓存不一致性问题。无论是 Windows 系统，还是 Linux 系统，它们都有特定的内存模型。**

简单的CPU Cache示意图：

![image.png](%E5%B9%B6%E5%8F%91%20137aa808854d49ceab1550336a1e46f2/image%201.png)

CPU Cache的工作方式：先复制一份数据到CPU Cache中，当CPU需要用到的时候就可以直接从CPU Cache中读取数据，当运算完成后，再将运算得到的数据写回Main Memory中。

这里会存在 **内存缓存不一致的问题**，CPU为了解决内存缓存不一致性问题可以通过 定制 **缓存一致协议** 或者其他手段来解决。

操作系统通过  **内存模型（Memory Model）** 定义一系列规范来解决这个问题，无论是Windows还是Linux，它们都有特定的内存模型。

## **3.2 指令重排序**

执行代码的时候并不一定是按照你写的代码的顺序依次执行。

常见的两种指令重排的情况：

1、编译器优化重排：编译器（包括 JVM、JIT 编译器等）在不改变单线程程序语义的前提下，重新安排语句的执行顺序。

2、**指令并行重排**：现代处理器采用了指令级并行技术(Instruction-Level Parallelism，ILP)来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。

Java 源代码会经历 **编译器优化重排 —> 指令并行重排 —> 内存系统重排** 的过程，最终才变成操作系统可执行的指令序列。

## **3.3 JMM(Java Memory Model)**

一般来说，编程语言也可以直接复用操作系统层面的内存模型。不过，不同的操作系统内存模型不同。如果直接复用操作系统层面的内存模型，就可能会导致同样一套代码换了一个操作系统就无法执行了。**Java 语言是跨平台的，它需要自己提供一套内存模型以屏蔽系统差异。**

对于 Java 来说，你可以把 JMM 看作是 Java 定义的并发编程相关的一组规范，除了抽象了线程和主内存之间的关系之外，其还规定了从 Java 源代码到 CPU 可执行指令的这个转化过程要遵守哪些和并发相关的原则和规范，**其主要目的是为了简化多线程编程，增强程序可移植性的。**

**为什么要遵守这些并发相关的原则和规范呢？**

这是因为并发编程下，像 CPU 多级缓存和指令重排这类设计可能会导致程序运行出现一些问题。就比如说我们上面提到的指令重排序就可能会让多线程程序的执行出现问题，为此，JMM 抽象了 happens-before 原则（后文会详细介绍到）来解决这个指令重排序问题。

## **3.4 JMM是如何抽象线程与主内存之间的关系？**

**Java 内存模型（JMM）** 抽象了线程和主内存之间的关系，就比如说**线程之间的共享变量必须存储在主内存中。JMM将内存分为两类抽象 主内存 和 工作内存.**

- **什么是主内存？什么是本地内存？**

**主内存**：所有线程创建的实例对象都存放在主内存中，不管该实例对象是成员变量，还是局部变量，类信息、常量、静态变量都是放在主内存中。为了获取更好的运行速度，虚拟机及硬件系统可能会让工作内存优先存储于寄存器和高速缓存中。

**本地内存**：每个线程都有一个私有的本地内存，本地内存存储了该线程以读 / 写共享变量的副本。**每个线程只能操作自己本地内存中的变量，无法直接访问其他线程的本地内存。**

如果线程间需要通信，必须通过 **主内存** 来进行。本地内存是 JMM 抽象出来的一个概念，并不真实存在，它涵盖了缓存、写缓冲区、寄存器以及其他的硬件和编译器优化。

![image.png](%E5%B9%B6%E5%8F%91%20137aa808854d49ceab1550336a1e46f2/image%202.png)

从上图来看，线程 1 与线程 2 之间如果要进行通信的话，必须要经历下面 2 个步骤：

Step1、线程 1 把本地内存中修改过的共享变量副本的值同步到主内存中去。

Step2、线程 2 到主存中读取对应的共享变量的值。

**JMM 为共享变量提供了可见性的保障。**

多线程下，对主内存中的一个共享变量进行操作有可能诱发线程安全问题，所以Java内存模型也定义了多种同步操作：

**锁定（lock）**: 作用于主内存中的变量，将他标记为一个线程独享变量。

**解锁（unlock）**: 作用于主内存中的变量，解除变量的锁定状态，被解除锁定状态的变量才能被其他线程锁定。

## **3.5 Java内存区域和JMM有何区别？**

**Java 内存区域和内存模型是完全不一样的两个东西**：

- JVM 内存结构和 **Java 虚拟机的运行时区域相关**，定义了 JVM 在运行时如何分区存储程序数据，就比如说堆主要用于存放对象实例。
- Java 内存模型和 Java 的并发编程相关，抽象了线程和主内存之间的关系就比如说**线程之间的共享变量必须存储在主内存中**，规定了从 Java 源代码到 CPU 可执行指令的这个转化过程要遵守哪些和并发相关的原则和规范，其主要目的是为了简化多线程编程，增强程序可移植性的。

# 4 Volatile

## 4.1 背景

在 Java 中，`volatile` 关键字可以**保证变量的可见性**，如果我们将变量声明为 **`volatile`** ，这就指示 JVM，这个变量是**共享且不稳定的**，每次使用它都到主存中进行读取。

![Untitled](%E5%B9%B6%E5%8F%91%20137aa808854d49ceab1550336a1e46f2/Untitled.png)

注：`volatile` 关键字能保证数据的可见性，但不能保证数据的原子性。`synchronized` 关键字两者都能保证。

如果想要保证原子性的话得考虑加锁synchronized、AtomicInteger等

## **4.2 `volatile` 关键字的作用**

**1、保证变量对所有线程的可见性**

**2、禁止指令重排序优化**

如果我们将变量声明为**`volatile`**，在对这个变量进行读写操作的时候，会通过插入特定的 **内存屏障** 的方式来禁止指令重排序。

### 机制 ：内存屏障

对 `volatile` 变量的写操作，编译器会插入一个**写屏障（store barrier）**，确保在写入 `volatile` 变量**之前**，**所有之前的写操作都被刷新到主内存。**

对 `volatile` 变量的读操作，编译器会插入一个**读屏障（load barrier）**，确保在读取 `volatile` 变量**之后，所有后续的读操作都从内存中重新读取最新的值。**

### 为什么需要保证内存的可见性？

如果不保证内存可见性，就会出现**数据脏读，**一个线程修改了共享变量的值，但其他线程无法立即看到最新值，导致其他线程读取到了过期数据，从而产生错误的结果。

通过保证内存可见性，避免数据不一致性和 并发访问带来的问题，保证程序的正确性和稳定性。

# 5 CAS算法  实现乐观锁

## 5.1 悲观锁

悲观锁总是假设最坏的情况，共享资源每次只给一个线程使用，其他线程阻塞，使用完后再把资源转让给其他线程。

## 5.2 CAS算法

CAS 的全称是 **Compare And Swap（比较与交换）** ，用于实现乐观锁，用一个预期值和要更新的变量值进行比较，两值相等才会进行更新。
CAS 是一个**原子操作**，底层依赖于一条 **CPU 的原子指令（考过）**。CAS 涉及到三个操作数：

**V**：要更新的变量值(Var)

**E**：预期值(Expected)

**N**：拟写入的新值(New) 

**当且仅当 V 的值等于 E 时，CAS 通过原子方式用新值 N 来更新 V 的值。如果不等，说明已经有其它线程更新了 V，则当前线程放弃更新。**

当多个线程同时使用 CAS 操作一个变量时，**只有一个会胜出，并成功更新，其余均会失败**，但失败的线程并不会被挂起，**仅是被告知失败，并且允许再次尝试**，当然也允许失败的线程放弃操作。

例：多线程执行count++,可以使用synchronized 或 `ReentrantLock` 都可以实现对资源加锁，保证其并发性，但是由于其被串行化了，一次只运行一个线程访问资源，导致效率大大降低。count++实际上是3步：1、获取count值，A = count 2、将A+1得到B：B = A+1 3、将B值赋值给count count = A+1  

实际上只针对3，我们可以使用CAS，也就是一种粒度更细的锁去保证我们的效率，

1、获取锁（CAS）

2、获取当前的count值

3、当前count值是否等于A，相等count = B,不相等则放弃更新（自旋？）

4、释放锁

乐观锁的实现一般用版本号机制或CAS算法实现

### **版本号机制**

一般是在数据表上加上一个数据版本号version字段，**表示数据被修改的次数。但数据被修改时，version值会加一。**

当线程A要更新数据值时，在读取数据的同时也会读取version值，在提交 更新时，若刚才 **读到的version值为当前数据库的version值相等时** 才更新，否则重试更新操作，直到更新成功。

## **5.3 Java中实现CAS（重点关注）**

在 Java 中，实现 CAS（Compare-And-Swap, 比较并交换）操作的一个关键类是`Unsafe`。`Unsafe`类位于`sun.misc`包下，是一个提供**低级别、不安全操作**的类。
`sun.misc`包下的`Unsafe`类提供了`compareAndSwapObject` 、`compareAndSwapInt`、`compareAnd-SwapLong`方法来实现的对`Object`、`int`、`long`类型的 CAS 操作。
由于 CAS 操作可能会因为并发冲突而失败，因此通常会与`while`循环搭配使用，在失败后不断重试，直到操作成功。这就是 **自旋锁机制** 。

### Unsafe类（了解）

提供一些 **更底层的**，**访问系统内存资源**，和 **管理系统内存资源** 的方法，但是因为会访问系统的内存资源 变成和C语言一样的指针，指针的使用是**有风险**的，所以Unsafe也是有类似的风险。

Unsafe类提供的功能实现是依赖于**本地方法（Native Method）**本地方法是Java中使用其他语言写的方法，java只负责声明。

## 5.4 ABA问题—CAS可能存在问题

CAS在操作值时，检查下值有没有变化，如果没有变化则更新。但，如果一个值原来是A，CAS执行前被另一个线程修改成了B，然后又修改为A，CAS检查时会发现它的值没有变化，但实际上，它被另一个线程影响了。

解决思路：ABA 问题的解决思路是在变量前面追加上**版本号或者时间戳**。JDK 1.5 以后的 `AtomicStampedReference` 类就是用来解决 ABA 问题的，其中的 `compareAndSet()` 方法就是首先检查当前引用是否等于预期引用，并且当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。
注：CAS另一个可能存在的问题是一直自旋，循环开销很大。其中的 `compareAndSet()` 方法就是首先检查当前引用是否等于预期引用，并且当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值。
解决：如果 JVM 能够支持处理器提供的`pause`指令，那么自旋操作的效率将有所提升。

## 5.5 CAS为什么要判断内存里的值和旧值是否相等，举个例子？

**比较操作确保了：**

1. **值未被其他线程修改过** 才执行更新
2. 如果发现值已被修改，则放弃当前操作
3. 避免了多线程下的数据竞争和不一致

**举例：**

假设有两个线程同时要给同一个账户余额(初始值=100)增加50元；

时刻T0：线程A读取余额=100(旧值)，准备更新为150

时刻T1：线程B读取余额=100(旧值)，准备更新为150

如果没有比较步骤的话：线程B会直接用150覆盖当前值150，最终结果是150而不是正确的200，相当于线程A的50元增加被线程B的50元增加覆盖了。

## 5.6 Atomic 原子类

`java.util.concurrent.atomic` 包提供了一些用于原子操作的类。这些类利用底层的原子指令(操作不可分割、不可中断，即使在多个线程同时执行时，该操作要么全部执行完成，要么不执行)，确保在多线程环境下的操作是线程安全的。

![image.png](%E5%B9%B6%E5%8F%91%20137aa808854d49ceab1550336a1e46f2/image%203.png)

根据操作的数据类型，可以将JUC包中的原子类分为四类：

1、基本类型  2、数组类型  3、引用类型  4、对象的属性修改类型

## 5.7 循环时间长开销大

CAS 经常会用到自旋操作来进行重试，也就是不成功就一直循环执行直到成功。如果长时间不成功，会给 CPU 带来非常大的执行开销。

**JVM 能够支持处理器提供的`pause`指令**，那么自旋操作的效率将有所提升。`pause`指令有两个重要作用：

- **延迟流水线执行指令**：**`pause`指令可以延迟指令的执行**，从而减少 CPU 的资源消耗。具体的延迟时间取决于处理器的实现版本，在某些处理器上，延迟时间可能为零。
- **避免内存顺序冲突**：在退出循环时，`pause`指令可以避免由于内存顺序冲突而导致的 CPU 流水线被清空，从而提高 CPU 的执行效率。

## 5.8 AtomicReference

**CAS 操作仅能对单个共享变量有效。**当需要操作多个共享变量时，CAS 就显得无能为力。不过，从 JDK 1.5 开始，Java 提供了 AtomicReference

类，这使得我们能够保证引用对象之间的原子性。通过将多个变量封装在一个对象中，我们可以使用 AtomicReference 来执行 CAS 操作。

# 6 Thread Local

## 6.1 基本认识

`ThreadLocal`类主要解决的就是让 **每个线程绑定自己的值**，可以将`ThreadLocal`类形象的比喻成存放数据的盒子，盒子中可以存储 **每个线程的私有数据**。实现每一个线程都有自己的 专属本地变量。

主要用于解决不同线程间的 **数据隔离问题**。 **（其他问题线程并发问题则难以解决）**

如果你创建了一个`ThreadLocal`变量,那么访问这个变量的每个线程都会有这个变量的本地副本，这也是`ThreadLocal`变量名的由来。他们可以使用 `get()` 和 `set()` 方法来获取默认值或将其值更改为当前线程所存的副本的值，从而避免了线程安全问题

## 6.2 原理

`Thread` 类中有一个 `threadLocals` 和 一个 `inheritableThreadLocals` 变量。

它们都是 `ThreadLocalMap` 类型的变量,我们可以把 `ThreadLocalMap` 理解为`ThreadLocal` 类实现的定制化的 `HashMap` 。

默认情况下这两个变量都是 null，只有当前线程调用 `ThreadLocal` 类的 `set`或`get`方法时才创建它们，实际上调用这两个方法的时候，我们调用的是`ThreadLocalMap`类对应的 `get()`、`set()`方法。

**最终的变量是放在了当前线程的 `ThreadLocalMap` 中，并不是存在 `ThreadLocal` 上，`Thread-Local` 可以理解为只是`ThreadLocalMap`的封装，传递了变量值每个`Thread`中都具备一个`ThreadLocalMap`，而`ThreadLocalMap`可以存储以`ThreadLocal`为 key ，Object 对象为 value 的键值对。**

![Untitled](%E5%B9%B6%E5%8F%91%20137aa808854d49ceab1550336a1e46f2/Untitled%201.png)

底层相当于一个哈希Map

**`ThreadLocalMap`是`ThreadLocal`的静态内部类。**

![image.png](%E5%B9%B6%E5%8F%91%20137aa808854d49ceab1550336a1e46f2/image%204.png)

## 6.3 内存泄漏

`ThreadLocalMap` 中使用的 key 为 `ThreadLocal` 的 **弱引用**，而 value 是 **强引用**。所以，如果 `ThreadLocal` 没有被外部强引用的情况下，**在垃圾回收的时候，key 会被清理掉，而 value 不会被清理掉。**
这样一来，`ThreadLocalMap` 中就会出现 key 为 null 的 Entry。**假如我们不做任何措施的话，value 永远无法被 GC 回收，这个时候就可能会产生内存泄露。**
`ThreadLocalMap` 实现中已经考虑了这种情况，在调用 `set()`、`get()`
`remove()` 方法的时候，会清理掉 key 为 null 的记录。使用完 `ThreadLocal`方法后最好手动调用`remove()`方法。

如果一个对象只具有弱引用，那就类似于**可有可无的生活用品**。弱引用与软引用的区别在于：只具有弱引用的对象拥有更短暂的生命周期。在垃圾回收器线程扫描它 所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。

## 6.4 线程池使用ThreadLocal的注意事项（多次考察过）

**1、避免内存泄漏：**`ThreadLocal`变量在被线程使用后，如果没有及时清理，可能会导致内存泄漏。解决方法：在任务执行完毕后，显式调用`ThreadLocal.remove()`方法来清理`ThreadLocal`变量。

**2、线程复用导致上下文冲突：**线程池中线程是可重用的，这意味着同一个线程可能在不同时间执行不同的任务，如果`ThreadLocal`变量没有及时清理，下一个任务可能会访问到上一个任务遗留下来的数据，导致数据混乱。解决方法：**确保每次任务执行前和执行后都清理`ThreadLocal`变量**。

**3、合理设置线程池大小**：线程池的大小和类型也会影响**`ThreadLocal`**的使用。如果线程池过大，可能导致过多的**`ThreadLocal`**变量占用内存；如果过小，可能会导致线程复用过频，引发上下文冲突。

## 6.5 ThreadLocal的作用

**1、线程隔离** ： ThreadLocal **为每个线程提供了独立的变量副本，这意味着线程之间不会相互影响，**可以安全地在多线程环境中使用这些变量而不用担心数据竞争或同步问题。

**2、降低耦合度** ： 在同一个线程内的多个函数或组件之间，使用ThreadLocal可以减少参数的传递，降低代码之间的耦合度。

**3、性能优势** ： 由于ThreadLocal避免了线程间的同步开销，所以在大量线程并发执行时，相比传统的锁机制，它可以提供更好的性能。

## 6.6 ThreadLocal解决哈希冲突(这里和普通的hashmap有区别)

ThreadLocalMap是ThreadLocal的内部静态类，但使用**开放地址法而非链地址法**。当发生哈希冲突时，ThreadLocalMap会通过**线性探测法**寻找到下一个空闲槽位，直到找到合适的位置。

依次检查下一个槽位，直到找到合适位置。在探测过程中，清理遇到的过期条目。

## 6.7 ThreadLocal的使用场景

**1、数据库连接：**在多线程环境中，每个线程需要独立的数据库连接对象。

**2、会话信息：**如用户登录状态等，每个线程处理不同的用户请求时，可以使用ThreadLocal来保存这些信息。

**3、日志记录：**每个线程可能需要独立的日志上下文，例如事务ID或请求ID。

## 6.8 ThreadLocal的共享 与 父子线程间的共享（跨线程传递ThreadLocal的值）

ThreadLocal 的设计初衷是为每个线程提供独立的变量副本，避免线程安全问题。但确实有方法可以实现 ThreadLocal 的共享，以及在父子线程间传递数据。

常规的ThreadLocal实例在每个线程中都有独立的副本，线程间默认不共享

**实现 ThreadLocal 共享的方法 → 使用 InheritableThreadLocal**

**`InheritableThreadLocal`** 是 ThreadLocal 的子类，允许子线程继承父线程的值。

完成ThreadLocal值的传递：创建Thread线程时，拿到父线程的 `inheritableThreadLocals` 变量赋值给子线程即可。相关代码如下：

```java
InheritableThreadLocal<String> inheritableThreadLocal = new InheritableThreadLocal<>();

inheritableThreadLocal.set("Main thread value");

new Thread(() -> {
    System.out.println(inheritableThreadLocal.get()); // 输出 "Main thread value"
}).start();
```

还有一种方法：TransmittableThreadLocal ： TransmittableThreadLocal （简称 TTL） 是阿里巴巴开源的工具类，继承并加强了InheritableThreadLocal类，可以在线程池的场景下支持 ThreadLocal 值传递。

## 6.9 ThreadLocalMap扩容机制

当前散列数组中`Entry`的数量已经达到了列表的扩容阈值`(len*2/3)`，就开始执行`rehash()`逻辑。

Step1、首先是会进行探测式清理工作，从table的起始位置往后清理，上面有分析清理的详细流程。清理完成之后，table中可能有一些key为null的Entry数据被清理掉，所以此时通过判断size >= threshold * 3/4 来决定是否扩容。

进行`rehash()`的阈值是`size >= threshold`清理过后size >= threshold * 3/4

![image.png](%E5%B9%B6%E5%8F%91%20137aa808854d49ceab1550336a1e46f2/image%205.png)

Step2、扩容后的tab的大小为oldLen * 2，然后遍历老的散列表，重新计算hash位置，然后放到新的tab数组中，如果出现hash冲突则往后寻找最近的entry为null的槽位，遍历完成之后，oldTab中所有的entry数据都已经放入到新的tab中了。

# 7 synchronized关键字

`synchronized` 是 Java 中的一个关键字，主要解决的是多个线程之间访问资源的同步性，可以保证 **被它修饰的方法或者代码块** 在 **任意时刻只能有一个线程执行。**

早期版本是重量级锁，后期加入了大量锁优化，提升了synchronized的效率。

## 7.1 使用

`synchronized` 关键字的使用方式主要有下面 3 种：

1. 修饰实例方法。
2. 修饰静态方法。
3. 修饰代码块。

### 构造方法不能用synchronized关键字

可以在 **构造方法内部** 使用 **synchronized 代码块。**

构造方法本身是线程安全的，但如果在构造方法中涉及到共享资源的操作，就需要采取适当的同步措施来保证整个构造过程的线程安全。

## 7.2 底层原理

synchronized同步语句块的实现使用的是 `monitorenter` 和 `monitorexit` 指令，其中 `monitorenter` 指令指向同步代码块的开始位置，`monitorexit` 指令则指明同步代码块的结束位置。

在执行`monitorenter`时，会尝试获取对象的锁，如果锁的计数器为 0 则表示锁可以被获取，获取后将锁计数器设为 1 也就是加 1。

![Untitled](%E5%B9%B6%E5%8F%91%20137aa808854d49ceab1550336a1e46f2/Untitled%202.png)

对象锁的的拥有者线程才可以执行 `monitorexit` 指令来释放锁。在执行 `monitorexit` 指令后，将锁计数器设为 0，表明锁被释放，其他线程可以尝试获取锁。

![Untitled](%E5%B9%B6%E5%8F%91%20137aa808854d49ceab1550336a1e46f2/Untitled%203.png)

## 7.3 synchronized和volatile有什么区别？

**两者是互补的关系，并不是对立的。**

1、`volatile` 关键字是线程同步的**轻量级实现**，所以 `volatile`性能肯定比`synchronized`关键字要好 ；但是 **`volatile` 关键字只能用于变量**而 **`synchronized` 关键字可以修饰方法以及代码块 。**
2、`volatile` 关键字能保证数据的可见性，但不能保证数据的原子性。`synchronized` 关键字两者都能保证。

3、`volatile`关键字主要用于解决变量在多个线程之间的可见性，而 `synchronized` 关键字解决的是多个线程之间访问资源的同步性。 

## 7.4 不同版本的synchronized的变化

- 在Java早期版本中，synchronized属于**重量级锁，**效率低下**，**这是因为监视器锁（monitor）是依赖于底层的操作系统的 `Mutex Lock` 来实现的，Java 的线程是映射到操作系统的原生线程之上的。**如果要挂起或者唤醒一个线程，都需要操作系统帮忙完成，而操作系统实现线程之间的切换时需要从用户态转换到内核态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高。**
- 在 **Java 6 之后**， **`synchronized` 引入了大量的优化如自旋锁、适应性自旋锁、锁消除、锁粗化、偏向锁、轻量级锁等技术来减少锁操作的开销。**

## 7.5 锁的四种状态（JDK1.6中引入）

锁主要存在四种状态，依次是：**无锁状态（No Lock）、偏向锁状态(无竞争)、轻量级锁状态（竞争不激烈）、重量级锁状态（强烈竞争）**，他们会随着竞争的激烈而逐渐升级。注意**锁可以升级不可降级**，这种策略是为了提高获得锁和释放锁的效率。

- 偏向锁是为了在**没有竞争**的情况下进一步优化性能。当一个线程首次获得锁时，JVM将偏向锁定给该线程，并在对象头中记录线程ID。如果同一个线程再次进入同步块，JVM将 **不再执行同步操作，从而减少开销** 。偏向锁的适用场景是大多数情况下锁只有一个线程访问。偏向锁在没有竞争的情况下性能非常高，但如果出现竞争，偏向锁会被撤销，并升级为轻量级锁。
- 轻量级锁是通过使用CAS（Compare-And-Swap）操作来实现的。当一个线程尝试获取一个已经偏向其他线程的锁时，偏向锁会被撤销，锁会升级为轻量级锁。轻量级锁适用于 **短时间的竞争情况。如果竞争不激烈，**轻量级锁的性能会很好，因为它避免了重量级锁的开销。然而，如果竞争激烈，锁会再次升级。
- 当轻量级锁无法满足同步要求时，锁会升级为重量级锁，也称为监视器锁（Monitor Lock）。重量级锁使用操作系统的互斥锁机制，线程会进入阻塞状态，直到获得锁。

### **synchronized偏向锁直接升级为重量级锁吗？重量级锁怎么实现的？**

现代JVM对synchronized进行了多种优化（偏向锁、自旋锁），使其在某些情况下表现更高效、更灵活的行为。

偏向锁不会直接升级为重量级锁，而是会先升级为轻量级锁，如果轻量级锁竞争失败，则再升级为重量级锁。重量级锁的实现一般是通过操作系统的**互斥量（mutex）**来实现的。当一个线程获取重量级锁时，会将该线程挂起，直到锁被释放。这种锁的性能比较低，因为每次加锁和释放锁都需要涉及到操作系统的系统调用，会有较大的开销。因此，在实际应用中，要**尽量避免使用重量级锁。**

# 8 `ReentrantLock`

`ReentrantLock` 实现了 `Lock` 接口，是一个**可重入且独占式**的锁，和 `synchronized` 关键字类似，但增加了轮询、超时、中断、公平锁和非公平锁等高级功能

## 8.1 可重入锁（也很重要）

**可重入锁**也叫递归锁，指的是线程**可以再次获取自己的内部锁**。比如一个线程获得了某个对象的锁，此时这个对象锁还没有释放，当其再次想要获取这个对象的锁的时候还是可以获取的，**如果是不可重入锁的话，就会造成死锁。`synchronized` 关键字锁和`ReentrantLock` 都是可重入的。**

### ReentrantLock 实现可重入锁

基于**线程持有锁的计数器**

1、当一个线程第一次获取锁时，计数器会加1，表示该线程持有了锁。在此之后，如果同一个线程再次获取锁，计数器会再次加1.每次线程成功获取锁时，都会将计数器加1。

2、当线程释放锁时，计数器会相应的减1。**只有当计数器减到0时，锁才会完全释放，其他线程才有机会获取锁。**

### synchronized实现可重入锁（synchronized实现可重入锁也很重要）

synchronized 是基于 原子性 的内部锁机制，**是可重入的，**因此在一个线程调用synchronized方法的同时，在其方法体内部调用该对象另一个synchronized方法，**也就是说一个线程得到一个对象锁后，再次请求该对象锁， 是允许的**，这就是synchronized的可重入性。

synchronized底层是利用**计算机系统mute Lock**实现的。每一个重入锁都会关联一个线程ID和一个锁状态status。

当一个线程请求方法时，会去检查锁状态：

1、如果锁状态是0，代表该锁没有被占用，使用CAS操作获取锁，将线程ID替换成自己的线程ID

2、如果锁状态不是0，代表有线程在访问该方法。此时，**如果线程ID是自己的线程ID，如果是可重入锁，会将status自增1，然后获取到该锁，进而执行相应的方法；如果是非重入锁，就会进入阻塞队列等待。**

在释放锁时：

1、如果是可重入锁的，每一次退出方法，就会将status减1，直至status的值为0，最后释放该锁。

2、如果非可重入锁的，线程退出方法，直接就会释放该锁。

## 8.2`ReentrantLock` 与`synchronized` 的区别

在高竞争场景下，ReentrantLock可能比synchronized具有更好的性能，因为它提供了更多的优化选项。

**1、 底层实现不同：**`synchronized` **依赖于JVM， JVM 层面通过监视器实现的，**`ReentrantLock` 于 **AQS 实现**的。

**2、可中断的锁等待：**`ReentrantLock`**等待可中断**，`ReentrantLock`提供了一种能够中断等待锁的线程的机制，也就是说正在等待的线程可以选择放弃等待，改为处理其他事情。**（解决死锁问题）**而 synchronized 不能响应中断。

**3、锁类型不同：**`ReentrantLock`**可实现公平锁** ，`ReentrantLock`可以指定是公平锁还是非公平锁（如下所示），synchronized 属于非公平锁。

**4、用法不同**：**`ReentrantLock`只能用在代码块上**，`synchronized` ****可用来修饰普通方法、静态方法和代码块。

**5、支持超时：**`ReentrantLock` 提供了 `tryLock(timeout)` 的方法，可以指定等待获取锁的最长等待时间，如果超过了等待时间，就会获取锁失败，不会一直等待。

### 注：**可中断锁和不可中断锁有什么区别**？

- **可中断锁**：获取锁的过程中可以被中断，不需要一直等到获取锁之后 才能进行其他逻辑处理。`ReentrantLock` 就属于是可中断锁。
- **不可中断锁**：一旦线程申请了锁，就只能等到拿到锁以后才能进行其他的逻辑处理。 `synchronized` 就属于是不可中断锁。

## 8.3 ReentrantReadWriteLock

读写锁：`ReentrantReadWriteLock` 实现了 `ReadWriteLock` ，是一个可重入的读写锁，既可以保证多个线程同时读的效率，同时又可以保证有写入操作时的线程安全。

在读多写少的情况下，使用ReentrantReadWriteLock能够明显提升系统的性能。

### 线程持有读锁还能获取写锁吗？

- 在线程持有读锁的情况下，该线程不能取得写锁(因为获取写锁的时候，如果发现当前的读锁被占用，就马上获取失败，不管读锁是不是被当前线程持有)。
- 在线程持有写锁的情况下，该线程可以继续获取读锁（获取读锁时如果发现写锁被占用，只有写锁没有被当前线程占用的情况才会获取失败）。

# 9 公平锁和非公平锁

锁可以分为公平锁和非公平锁，它们在**线程获取锁的顺序上有所不同**。

## 9.1 公平锁

**公平锁（Fair Lock）**是一种确保锁获取顺序与请求顺序相同的锁，即先请求锁的线程先获得锁。

**特点**

1. **先到先得**：线程获取锁的顺序是按照它们请求锁的顺序来决定的。
2. **避免饥饿**：因为是先到先得的策略，所以不会出现某个线程一直得不到锁的情况，**避免了线程饥饿现象。**
3. **性能开销**：由于公平锁需要维护一个请求队列，管理线程请求的顺序，所以相对非公平锁来说，**公平锁的性能开销较大，吞吐量较低。**

**实现方式**

在 Java 中，可以使用 **`ReentrantLock` 类的构造函数**来创建公平锁：

```java
ReentrantLock fairLock = new ReentrantLock(true);
```

## 9.2 非公平锁

**非公平锁（Non-Fair Lock）**是一种线程获取锁的顺序与请求顺序无关的锁，即**任何线程都可以随时尝试获取锁，而不考虑其他线程是否在等待锁。**

**特点**

1. **（问过）高吞吐量**：因为非公平锁不需要维护请求队列，线程可以直接尝试获取锁，所以相对公平锁来说，非公平锁的性能开销较小，吞吐量较高。非公平锁，当线程获取锁时，会先通过CAS尝试获取锁，如果获取成功就直接拥有锁，如果获取失败才会进入等待队列，等待下次尝试获取锁。获取锁不用遵循先到先得，从而避免了线程休眠与恢复的操作。
2. **可能出现饥饿**：由于线程可以随时尝试获取锁，可能会出现某些线程长时间得不到锁的情况，导致线程饥饿现象。
3. **实现简单**：非公平锁的实现相对简单，不需要管理线程请求的顺序。

**实现方式**

可以使用 `ReentrantLock` 类的构造函数来创建非公平锁，默认情况下，`ReentrantLock` 创建的是非公平锁。

```java
ReentrantLock nonfailLock = new ReentrantLock();
```

**注：**

`synchronized` 是**非公平锁**，没有保证线程获取锁的顺序。**ReentrantLock中的很多功能都是基于AQS去实现的。**

# 10. AQS  **AbstractQueuedSynchronizer**

AQS 提供了一种框架来**实现基于队列的同步器**，如独占锁（`ReentrantLock`）、共享锁（`ReadWriteLock`）、信号量（`Semaphore`）等。

```java
public abstract class AbstractQueuedSynchronizer extends AbstractOwnableSynchronizer implements java.io.Serializable {
}
```

本质上AQS是一个抽象类，为同步器提供了 **通用的执行框架**，可以看作是同步器的 **基础“底座”。**而同步器则是基于AQS的 **具体“应用”**

## 10.1  AQS原理

AQS通过使用一个 **volatile int类型的同步状态（state）来表示同步状态 以及 一个FIFO（先进先出）的等待队列来管理等待获取资源的线程。** 

**为什么会有一个队列？→ 避免竞争锁带来的饥饿问题，每个线程会作为一个节点加入到队列中，并通过自旋监控前一个线程节点的状态，而不是直接竞争共享变量，线程按顺序排队，确保公平性，从而避免了饥饿问题。**

### AQS核心组件

**1、状态变量state**

由 volatile 修饰的int类型变量，state = 0,当前共享资源未被加锁，state = 1,当前共享资源已被加锁。
对应的CAS操作方法：**final boolean compareAndSetState(){}**

这里state的具体含义，会根据具体实现类的不同而不同 ：

- 在 Semapore 里，他表示剩余许可证的数量；
- 在 CountDownLatch 里，它表示还需要倒数的数量；
- 在 ReentrantLock 中，state用来表示“锁”的占有情况，包括可重入计数，当state的值为0的时候，标识该Lock不被任何线程所占有。

state是volatile修饰的，并被并发修改，所以**修改state的方法都需要保证线程安全**，比如getState、setState以及CAS来读取和更新这个状态。这些方法都依赖于Unsafe类。

**2、FIFO等待队列**

AQS使用一个**双向链表**实现的FIFO队列来管理等待获取资源的线程。

队列中的每个节点（Node）代表一个等待线程，节点中保存了线程的引用、等待状态等信息。

**3、Node节点**

Node节点是AQS内部类，用于表示等待队列中的线程节点。

主要属性：

- int waitStatus ：节点的等待状态
- Node prev,Node next ：指向前驱和后继节点的指针
- Thread thread ： 等待的线程

### AQS工作原理

**1、获取资源**

线程调用 acquire(int arg) 方法尝试获取资源。

如果 **tryAcquire(int arg) 返回 true，表示获取成功，线程继续执行**。如果 **tryAcquire(int arg) 返回 false，线程会被包装成 Node 节点并加入等待队列，然后进入阻塞状态。**

![屏幕截图 2024-09-11 145133.png](%E5%B9%B6%E5%8F%91%20137aa808854d49ceab1550336a1e46f2/%25E5%25B1%258F%25E5%25B9%2595%25E6%2588%25AA%25E5%259B%25BE_2024-09-11_145133.png)

**如上图所示，thread-0一直持有锁，而thread-1、thread-2、thread-3、thread-4会被阻塞，所以他们会被放入到阻塞队列中。**

![屏幕截图 2024-09-11 145510.png](%E5%B9%B6%E5%8F%91%20137aa808854d49ceab1550336a1e46f2/%25E5%25B1%258F%25E5%25B9%2595%25E6%2588%25AA%25E5%259B%25BE_2024-09-11_145510.png)

**如上图所示，之后thread-0释放锁，thread-1会被唤醒，然后队列头元素出队**

**2、释放资源**

线程调用 release(int arg) 方法释放资源。
如果 tryRelease(int arg) 返回 true，表示释放成功，**AQS 会唤醒等待队列中的下一个线程**

### AQS中的常见状态

**1.同步状态（State）**

- **独占模式（Exclusive Mode）**

**获取锁**：线程尝试通过`acquire`方法获取锁，AQS通过调用自定义的`tryAcquire`方法来判断是否可以获取锁。**如果可以获取，则线程继续执行；如果无法获取，则线程进入等待队列，等待其他线程释放资源**
**释放锁**：线程通过`release`方法释放锁，AQS会调用`tryRelease`方法更新`state`，然后唤醒等待队列中的下一个线程。

- **共享模式**

**获取资源**：多个线程可以同时获取共享资源，AQS通过自定义的`tryAcquireShared`方法**来判断当前是否有足够的共享资源可供线程获取。若可以，线程获取资源；若不可以，线程加入等待队列。**

**释放资源**：当一个线程释放资源时，AQS通过`tryReleaseShared`方法更新资源的状态**，并唤醒其他等待的线程**

**2.等待队列中的状态（Node State）**

等待队列中的节点有以下几种重要状态:

- **SIGNAL**：表示后继节点需要被唤醒。当一个线程进入等待队列时，如果当前线程无法获取锁，**AQS会将它的节点状态设置为SIGNAL**，表示当前线程需要等待，并且在前驱节点释放锁时唤醒。
- **CANCELLED**：表示线程取消了等待。通常发生在线程等待超时或者被中断的情况。
- **CONDITION**：表示节点在等待某个条件，当一个线程调用ConditionObject.await()方法时，它会被加入条件队列并处于此状态，直到某个线程调用signal()来将其唤醒。
- **PROPAGATE**：用于共享模式，表示下一次获取资源应该传播唤醒动作。这在一些支持共享锁的机制中会用到。

## 10.2 自定义同步器

同步器的设计是基于模板方法模式的，如果需要自定义同步器一般的方式是这样（模板方法模式很经典的一个应用）：

- 使用者继承 `AbstractQueuedSynchronizer` 并重写指定的方法。
- 将 AQS 组合在自定义同步组件的实现中，并调用其模板方法，而这些模板方法会调用使用者重写的方法。

**AQS 使用了模板方法模式，自定义同步器时需要重写下面几个 AQS 提供的钩子方法：**

```java
//独占方式。尝试获取资源，成功则返回true，失败则返回false。
protected boolean tryAcquire(int)
//独占方式。尝试释放资源，成功则返回true，失败则返回false。
protected boolean tryRelease(int)
//共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。
protected int tryAcquireShared(int)
//共享方式。尝试释放资源，成功则返回true，失败则返回false。
protected boolean tryReleaseShared(int)
//该线程是否正在独占资源。只有用到condition才需要去实现它。
protected boolean isHeldExclusively()
```

**什么是钩子方法呢？** 钩子方法是一种被声明在抽象类中的方法，一般使用 `protected` 关键字修饰，它可以是空方法（由子类实现），也可以是默认实现的方法。

模板设计模式通过钩子方法控制固定步骤的实现。

## 10.3 常见同步工具类

### Semaphore(信号量)

`synchronized` 和 `ReentrantLock` 都是一次只允许一个线程访问某个资源**，而`Semaphore`(信号量)可以用来控制同时访问特定资源的线程数量。（state相当于许可证）**

```java
// 初始共享资源数量
final Semaphore semaphore = new Semaphore(5);
// 获取1个许可
semaphore.acquire();
// 释放1个许可
semaphore.release();
```

初始的资源个数为 1 的时候，`Semaphore` 退化为排他锁。

**`Semaphore` 有两种模式** 

**公平模式：** 调用 `acquire()` 方法的顺序就是获取许可证的顺序，遵循 FIFO；

**非公平模式：** 抢占式的。

- 构造方法：

**这两个构造方法，都必须提供许可的数量，第二个构造方法可以指定是公平模式还是非公平模式，默认非公平模式。**

```java
public Semaphore(int permits) {
    sync = new NonfairSync(permits);
}

public Semaphore(int permits, boolean fair) {
    sync = fair ? new FairSync(permits) : new NonfairSync(permits);
}
```

- **获取方法**

以无参 `acquire` 方法为例，调用`semaphore.acquire()` ，线程尝试获取许可证，如果 `state > 0` 的话，则表示可以获取成功，如果 `state <= 0` 的话，则表示许可证数量不足，获取失败。

如果可以获取成功的话(`state > 0` )，会尝试使用 CAS 操作去修改 `state` 的值 `state=state-1`。如果获取失败则会创建一个 Node 节点加入等待队列，挂起当前线程。

```java
// 获取1个许可证
public void acquire() throws InterruptedException {
    sync.acquireSharedInterruptibly(1);
}

// 获取一个或者多个许可证
public void acquire(int permits) throws InterruptedException {
    if (permits < 0) throw new IllegalArgumentException();
    sync.acquireSharedInterruptibly(permits);
}
```

`acquireSharedInterruptibly`方法是 `AbstractQueuedSynchronizer` 中的默认实现。

```java
// 共享模式下获取许可证，获取成功则返回，失败则加入等待队列，挂起线程
public final void acquireSharedInterruptibly(int arg)
    throws InterruptedException {
    if (Thread.interrupted())
      throw new InterruptedException();
        // 尝试获取许可证，arg为获取许可证个数，当获取失败时,则创建一个节点加入等待队列，挂起当前线程。
    if (tryAcquireShared(arg) < 0)
      doAcquireSharedInterruptibly(arg);
}
```

非公平模式（`NonfairSync`）的为例，看看 `tryAcquireShared` 方法的实现。

```java
// 共享模式下尝试获取资源(在Semaphore中的资源即许可证):
protected int tryAcquireShared(int acquires) {
    return nonfairTryAcquireShared(acquires);
}

// 非公平的共享模式获取许可证
final int nonfairTryAcquireShared(int acquires) {
    for (;;) {
        // 当前可用许可证数量
        int available = getState();
        /*
         * 尝试获取许可证，当前可用许可证数量小于等于0时，返回负值，表示获取失败，
         * 当前可用许可证大于0时才可能获取成功，CAS失败了会循环重新获取最新的值尝试获取
         */
        int remaining = available - acquires;
        if (remaining < 0 ||
            compareAndSetState(available, remaining))
            return remaining;
    }
}
```

- **释放方法**

以无参 `release` 方法为例，调用`semaphore.release();` ，线程尝试释放许可证，并使用 CAS 操作去修改 `state` 的值 `state=state+1`。
释放许可证成功之后，同时会唤醒等待队列中的一个线程。被唤醒的线程会重新尝试去修改 `state` 的值 `state=state-1` ,如果 `state > 0` 则获取令牌成功，否则重新进入等待队列，挂起线程。

```java
// 释放一个许可证
public void release() {
    sync.releaseShared(1);
}

// 释放一个或者多个许可证
public void release(int permits) {
    if (permits < 0) throw new IllegalArgumentException();
    sync.releaseShared(permits);
}
```

`releaseShared`方法是 `AbstractQueuedSynchronizer` 中的默认实现

```java
// 释放共享锁
// 如果 tryReleaseShared 返回 true，就唤醒等待队列中的一个或多个线程。
public final boolean releaseShared(int arg) {
    //释放共享锁
    if (tryReleaseShared(arg)) {
      //释放当前节点的后置等待节点
      doReleaseShared();
      return true;
    }
    return false;
}
```

### **CountDownLatch (倒计时器)**

CountDownLatch是基于AQS实现的，是Java并发包中的一个同步工具类

`CountDownLatch` 允许 `count` 个线程**阻塞**在一个地方，直至所有线程的任务都执行完毕。

`CountDownLatch` **是一次性的，**计数器的值只能在构造方法中初始化一次，之后没有任何机制再次对其设置值，**当 `CountDownLatch` 使用完毕后，它不能再次被使用。**

**原理**

`CountDownLatch` 是共享锁的一种实现，它默认构造 AQS 的 `state` 值为 `count`。

```java
public CountDownLatch(int count) {
    if (count < 0) throw new IllegalArgumentException("count < 0");
    this.sync = new Sync(count);
}

private static final class Sync extends AbstractQueuedSynchronizer {
    Sync(int count) {
        setState(count);
    }
  //...
}
```

当线程调用 `countDown()` 时，其实使用了`tryReleaseShared`方法以 CAS 的操作来减少 `state`，直至 `state` 为 0 。

当 `state` 为 0 时，表示所有的线程都调用了 `countDown` 方法，那么在 `CountDownLatch` 上等待的线程就会被唤醒并继续执行。 

```java
public void countDown() {
    // Sync 是 CountDownLatch 的内部类 , 继承了 AbstractQueuedSynchronizer
    sync.releaseShared(1);
}
```

`releaseShared`方法是 `AbstractQueuedSynchronizer` 中的默认实现。

```java
// 释放共享锁
// 如果 tryReleaseShared 返回 true，就唤醒等待队列中的一个或多个线程。
public final boolean releaseShared(int arg) {
    //释放共享锁
    if (tryReleaseShared(arg)) {
      //释放当前节点的后置等待节点
      doReleaseShared();
      return true;
    }
    return false;
}
```

 

```java
// 对 state 进行递减，直到 state 变成 0；
// 只有 count 递减到 0 时，countDown 才会返回 true
protected boolean tryReleaseShared(int releases) {
    // 自选检查 state 是否为 0
    for (;;) {
        int c = getState();
        // 如果 state 已经是 0 了，直接返回 false
        if (c == 0)
            return false;
        // 对 state 进行递减
        int nextc = c-1;
        // CAS 操作更新 state 的值
        if (compareAndSetState(c, nextc))
            return nextc == 0;
    }
}
```

## CyclicBarrier(循环栅栏)

`CyclicBarrier` 和 `CountDownLatch` 非常类似，它也可以实现线程间的技术等待，但是它的功能比 `CountDownLatch` 更加复杂和强大。主要应用场景和 `CountDownLatch` 类似。
**`CountDownLatch` 的实现是基于 AQS 的，而 `CycliBarrier` 是基于 `ReentrantLock ReentrantLock` 也属于 AQS 同步器)和 `Condition` 的。**

`CyclicBarrier` 的字面意思是可循环使用（Cyclic）的屏障（Barrier）。它要做的事情是：让一组线程到达一个屏障（也可以叫同步点）时被阻塞，直到最后一个线程到达屏障时，**屏障才会开门**，所有被屏障拦截的线程才会继续干活。（有点炉石的那种拒之门外的感觉了）

原理：

`CyclicBarrier` 内部通过一个 `count` 变量作为计数器，`count` 的初始值为 `parties` 属性的初始化值，每当一个线程到了栅栏这里了，那么就将计数器减 1。如果 count 值为 0 了，表示这是这一代最后一个线程到达栅栏，就尝试执行我们构造方法中输入的任务。（这和CountDownLatch一模一样）

### CountDownLatch和CyclicBarrier的区别：

**1、使用场景：**
• `CountDownLatch` 适用于一个或多个线程**等待其他多个线程完成某个事件**，典型用例如主线程等待多个工作线程完成初始化。
• `CyclicBarrier` 适用于**一组线程在每个阶段都需要相互等待**的情况，典型用例如并行计算任务中的各阶段同步。

**2、是否可重用：**

- `CountDownLatch` **是一次性的，**计数器一旦到达零就不能重用。
- `CyclicBarrier` **是可重用的**，在所有线程都到达屏障点后计数器会重置。

**3、额外功能：**

- `CyclicBarrier` 可以执行一个指定的触发器任务（`Runnable`），当所有线程到达屏障时触发。
- `CountDownLatch` 没有这样一个触发器功能。

**4、底层：**

- CountDownLatch 基于 AQS
- CyclicBarrier 基于 ReentrantLock 和 Condition

# 11 线程池

## 11.1 定义

线程池就是**管理一系列线程**的资源池。当有任务要处理时，直接从线程池中获取线程来处理，**处理完之后线程并不会立即被销毁，而是等待下一个任务。**

**池化技术的思想主要是为了减少每次获取资源的消耗，提高对资源的利用率。**

## 11.2 使用

**线程池**提供了一种限制和管理资源（包括执行一个任务）的方式。 每个**线程池**还维护一些基本统计信息，例如已完成任务的数量。

**方式一、通过`ThreadPoolExecutor`构造函数来创建（推荐）**

![image.png](%E5%B9%B6%E5%8F%91%20137aa808854d49ceab1550336a1e46f2/image%206.png)

**方式二、通过 `Executor` 框架的工具类 `Executors` 来创建。**通过`Executors`工具类可以创建多种类型的线程池（下面对线程池种类有详细的介绍）

工作流程

![Untitled](%E5%B9%B6%E5%8F%91%20137aa808854d49ceab1550336a1e46f2/Untitled%204.png)

## 11.3 `ThreadPoolExecutor` 参数

线程池的构造函数有7个参数：

![Untitled](%E5%B9%B6%E5%8F%91%20137aa808854d49ceab1550336a1e46f2/Untitled%205.png)

`corePoolSize` : 任务队列未达到队列容量时，**最大可以同时运行的线程数量。**

`maximumPoolSize` : 任务队列中存放的任务 **达到队列容量的时候**，当前可以同时运行的线程数量变为最大线程数。

`workQueue`: 新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。

**上面这三个是最重要的参数**

![Untitled](%E5%B9%B6%E5%8F%91%20137aa808854d49ceab1550336a1e46f2/Untitled%206.png)

注：`ThreadPoolExecutor` **默认不会回收核心线程**，即使它们已经空闲了。这是为了减少创建线程的开销，因为核心线程通常是要长期保持活跃的**（最大线程是可以被回收的）**
`keepAliveTime` ：当线程池中线程的数量大于corePoolSize，并且某个线程的空闲时间超过了keepAliveTime，那么这个线程就会被销毁。

`unit` :就是keepAliveTime时间的单位。

`threadFactory`：线程工厂。可以用来给线程取名字等等

`handler`：拒绝策略。当一个新任务交给线程池，如果此时线程池中有空闲的线程，就会直接执行，如果没有空闲的线程，就会将该任务加入到阻塞队列中，如果阻塞队列满了，就会创建一个新线程，从阻塞队列头部取出一个任务来执行，并将新任务加入到阻塞队列末尾。如果当前线程池中线程的数量等于maximumPoolSize，就不会创建新线程，就会去执行拒绝策略。

### **核心线程数一般设置为多少？**

经验设置，主要目的是优化资源利用率并最小化上下文切换开销

如果是 **CPU密集型应用** ，则线程池大小设置为 **N+1** ，线程的应用场景：主要是复杂算法 N保证每个CPU在同一时间只能执行一个线程，可最大化利用CPU资源。+1作为“溢出缓冲”

如果是 **IO密集型应用**，则线程池大小设置为 **2N+1**，线程的应用场景：主要是：数据库数据的交互，文件上传下载，网络数据传输等等。IO操作（如网络请求、磁盘读写）会阻塞线程，此时CPU空闲。更多线程线程可让CPU在等待IO时处理其他任务。

### 核心线程空闲时处于什么状态？

状态分为以下两种情况：

- **设置了核心线程的存活时间** ：核心线程在空闲时，会处于 `WAITING` 状态，等待获取任务。如果阻塞等待的时间超过了核心线程存活时间，则**该线程会退出工作，将该线程从线程池的工作线程集合中移除，线程状态变为 `TERMINATED` 状态。**
- **没有设置核心线程的存活时间** ：核心线程在空闲时，会一直处于 `WAITING` 状态，等待获取任务，核心线程会一直存活在线程池中。

**相关源码：**

线程在线程池内部被抽象为了 `Worker` ，当 `Worker` 被启动之后，会不断去任务队列中获取任务。

在获取任务的时候，会根据 `timed` 值来决定从任务队列（ `BlockingQueue` ）获取任务的行为。

如果「设置了核心线程的存活时间」或者「线程数量超过了核心线程数量」，则将 `timed` 标记为 `true` ，表明获取任务时需要使用 `poll()` 指定超时时间。

- `timed == true` ：使用 `poll()` 来获取任务。使用 `poll()` 方法获取任务超时的话，则当前线程会退出执行（ `TERMINATED` ），该线程从线程池中被移除。
- `timed == false` ：使用 `take()` 来获取任务。使用 `take()` 方法获取任务会让当前线程一直阻塞等待（`WAITING`）。

## 11.4 拒绝策略（考过）

如果当前同时运行的线程数量达到最大线程数量并且队列也已经被放满了任务时，`ThreadPoolExecutor` 定义一些策略:

### 11.4.1 **`AbortPolicy`**

**`ThreadPoolExecutor.AbortPolicy`**：抛出 `RejectedExecutionException`来拒绝新任务的处理。(直接拒绝新任务，Abort中止)

### 11.4.2`CallerRunsPolicy`

`ThreadPoolExecutor.CallerRunsPolicy`：调用执行自己的线程运行任务，也就是直接在调用`execute`方法的线程中运行(`run`)被拒绝的任务，如果执行程序已关闭，则会丢弃该任务。因此这种策略会降低对于新任务提交速度，影响程序的整体性能。如果你的应用程序可以承受此延迟并且你要求任何一个任务请求都要被执行的话，你可以选择这个策略。

**因此这种策略会降低对于新任务提交速度，影响程序的整体性能。如果走到`CallerRunsPolicy`的任务是个非常 耗时的任务，且处理提交任务的线程是主线程，可能会导致主线程阻塞，影响程序的正常运行。**

```java
public static class CallerRunsPolicy implements RejectedExecutionHandler {

        public CallerRunsPolicy() { }

        public void rejectedExecution(Runnable r, ThreadPoolExecutor e) {
            if (!e.isShutdown()) {
                // 直接主线程执行，而不是线程池中的线程执行
                r.run();
            }
        }
    }
```

### 11.4.3`DiscardPolicy`

`ThreadPoolExecutor.DiscardPolicy`：不处理新任务，直接丢弃掉。

### 11.4.4`DiscardOldestPolicy`

`ThreadPoolExecutor.DiscardOldestPolicy`：此策略将丢弃最早的未处理的任务请求。

## 11.5 线程池常用的阻塞队列（考过）

新任务来的时候会先判断当前运行的线程数量是否达到核心线程数，如果达到的话，新任务就会被存放在队列中。

**1、容量为 `Integer.MAX_VALUE` 的 `LinkedBlockingQueue`（有界阻塞队列）**`FixedThreadPool` 和 `SingleThreadExecutor` 。`FixedThreadPool`最多只能创建核心线程数的线程（核心线程数和最大线程数相等），`SingleThreadExecutor`只能创建一个线程（核心线程数和最大线程数都是 1），二者的任务队列永远不会被放满。

**2、`SynchronousQueue`（同步队列）：`CachedThreadPool` 。**

`SynchronousQueue` **没有容量，不存储元素**，目的是保证对于提交的任务，如果有空闲线程，则使用空闲线程来处理；否则新建一个线程来处理任务。也就是说，`CachedThreadPool` 的最大线程数是 `Integer.MAX_VALUE` ，可以理解为线程数是可以无限扩展的，可能会创建大量线程，从而导致 OOM（Out Of Memory,内存溢出）。

**3、`DelayedWorkQueue`（延迟队列）`ScheduledThreadPool` 和 `SingleThreadScheduledExecutor`** 

`DelayedWorkQueue` 的内部元素并不是按照放入的时间排序，而是会 **按照延迟的时间长短对任务进行排序，内部采用的是“堆”的数据结构**，可以保证每次出队的任务都是当前队列中执行时间最靠前的。`DelayedWorkQueue` 添加元素满了之后会自动扩容，增加原来容量的 50%，即永远不会阻塞，最大扩容可达 `Integer.MAX_VALUE`，所以最多只能创建核心线程数的线程。

---

如何设计一个能够**根据任务的优先级**来执行的线程池？

不同的线程池会选用不同的阻塞队列作为任务队列，假如我们需要实现一个优先级任务线程池的话，那可以考虑使用 `PriorityBlockingQueue` （优先级阻塞队列）作为任务队列，（`ThreadPoolExecutor` 的构造函数有一个 `workQueue` 参数可以传入任务队列）。
 `PriorityBlockingQueue` 实现对任务的排序：
1. 提交到线程池的任务实现 `Comparable` 接口，并重写 `compareTo` 方法来指定任务之间的优先级比较规则。

2.创建 `PriorityBlockingQueue` 时传入一个 `Comparator` 对象来指定任务之间的排序规则(推荐)。

## 11.6 线程池中线程异常，销毁还是复用？

**使用`execute()`时，未捕获异常导致线程终止，线程池创建新线程替代；**

**使用`submit()`时，异常被封装在`Future`中，线程继续复用。**
这种设计允许`submit()`提供更灵活的错误处理机制，因为它允许调用者决定如何处理异常，**而`execute()`则适用于那些不需要关注执行结果的场景。**

1、**使用`execute()`提交任务**：当任务通过`execute()`提交到线程池并在执行过程中抛出异常时，如果这个异常没有在任务内被捕获，那么该异常会导致当前线程终止。并且异常会被打印到控制台或日志文件中。线程池会检测到这种线程终止，并创建一个新线程来替换它，从而保持配置的线程数不变。

2、**使用`submit()`提交任务**：对于通过`submit()`提交的任务，如果在任务执行中发生异常，这个异常不会直接打印出来。相反，异常会被封装在由`submit()`返回的`Future`对象中。当调用`Future.get()`方法时，可以捕获到一个`ExecutionException`。在这种情况下，线程不会因为异常而终止，它会继续存在于线程池中，准备执行后续的任务。

### 线程池中某个线程挂了，线程池会执行什么操作？

**这里只针对用execute()提交任务。**

Step1、默认处理机制：**线程终止与补充**

**核心流程**：

1、线程抛出**未捕获异常**时，JVM 会终止该线程

2、线程池检测到工作线程死亡

3、若当前线程数 < 核心线程数，创建新线程补充

4、若允许核心线程超时(**`allowCoreThreadTimeOut=true`**)，则按需补充

Step2、异常捕获方案

**1、任务内捕获** 

```java
pool.execute(() -> {
    try {
        // 业务代码
    } catch (Exception e) {
        // 记录日志
        logger.error("Task failed", e);
    }
});
```

**2、Futrue捕获**

```java
//适用于需要获取任务执行结果的场景。
Future<?> future = pool.submit(() -> {
    throw new RuntimeException("Caught by Future");
});

try {
    future.get();
} catch (ExecutionException e) {
    logger.error("Task exception", e.getCause());
}
```

## 11.7线程池的关闭方法

### 11.7.1 **`shutdown()` 方法**

调用 `shutdown()` 方法后，线程池不再接受新的任务，**但会继续执行已提交的任务。所有正在执行和已提交的任务执行完成后，线程池会退出。**

**停止接收新任务 → 执行已提交任务 → 等待任务完成**

### 11.7.2 **`shutdownNow()` 方法**

调用 `shutdownNow()` 方法后，线程池会尝试停止所有正在执行的任务，并返回尚未开始执行的任务列表。该方法会中断所有正在执行的线程。**并返回未执行任务列表。**

**停止接收新任务 → 尝试中断正在执行的任务 → 返回未执行任务列表**

```java
public void shutdown(){} //shutdown()方法
public List<Runable> shutdownNow(){} //shutdownNow()方法，会返回一个链表。
```

## 11.8 核心线程数设置为0可不可以 ？

**可以，**当核心线程数为0的时候，会创建一个非核心线程进行执行。

## 11.9 提交给线程池中的任务可以被撤回吗？

可以，当向线程池提交任务时，会得到一个 Futrue 对象。这个 Futrue 对象提供了几种方法来管理任务的执行，包括取消任务。取消任务的主要方法是 Futrue 接口中的`cancel(boolean mayInterruptIfRunning)`方法

## 11.10 线程池的种类

### 1、**ScheduledThreadPool**

可以设置**定期的执行任务**，它支持定期或周期性的执行任务，比如每隔10秒执行一次任务。

### 2、FixedThreadPool（学成在线项目中用到的）

核心线程数和最大线程数是一样的，所以可以把它看作是固定线程数的线程池，它的特点是线程池的线程数量是固定的，任务数超过线程数，线程池不会再创建更多的线程来处理任务，而是会把超出线程处理能力的任务放到任务队列中进行等待。

### 3、CacheThreadPool

缓存线程池，特点是**线程数几乎可以是无限的**（最大可以达到Integer.MAX_VALUE）。

### 4、**SingleThreadExecutor**

它会使用唯一的线程去执行任务，原理和FixedThreadPool是一样的，只不过这里的线程只有一个，如果线程在执行任务的过程中发生异常，线程池会重新创建一个线程来执行后续的任务。

## 11.11 还有哪些地方用到了池化技术？

### 1、数据库连接池

数据库连接池管理数据库的连接，避免了每次请求数据库时都需要创建和销毁连接的开销。通过维持一定数量的数据库连接， 当应用程序需要访问数据库时，可以从池中取出一个已经存在的连接。

### 2、HTTP连接池

HTTP连接池管理HTTP连接，避免了每次请求都需要重新建立连接的开销。

### 3、信号量池

在OS和多线程应用中，信号量池用于管理信号量。通过池化信号量，可以减少信号量的创建和释放开销，提高资源的同步效率。

## 11.12 线程池有什么缺点？(线程数目过多)

**1、资源消耗**：每个线程都会**占用一定的内存（如栈空间）**，线程池中的线程数量过多可能导致内存消耗过大。

**2、CPU竞争：**如果线程池中的线程数量过多，线程上下文切换会消耗大量CPU周期，频繁的CPU切换会浪费时间。

**3、死锁风险**：如果线程池中的线程都在等待某个资源或任务完成，而该资源或任务又需要线程池中的线程来执行，可能会导致死锁。

## 11.13 相比异步创建一个线程执行任务，节约了哪些资源？

- **线程创建和销毁的开销**

创建成本：每次创建新线程需要分配内存、初始化线程栈等资源，这是相对昂贵的操作。销毁成本：线程结束时需要回收资源，频繁创建销毁会导致额外开销。

- **CPU资源**

上下文切换：线程过多会导致频繁的上下文切换，消耗CPU时间。线程池：通过控制线程数量，减少了不必要的上下文切换。

## 11.14 如何设计一个能够根据任务优先级来执行的线程池

我们需要实现一个优先级任务线程池的话，那可以考虑使用 **PriorityBlockingQueue （优先级阻塞队列）**作为任务队列**（ThreadPoolExecutor 的构造函数有一个 workQueue 参数可以传入任务队列）**

要想让 `PriorityBlockingQueue` 实现对任务的排序，传入其中的任务必须是具备排序能力的，方式有两种：

1. 提交到线程池的任务实现 `Comparable` 接口，并重写 `compareTo` 方法来指定任务之间的优先级比较规则。
2. 创建 `PriorityBlockingQueue` 时传入一个 `Comparator` 对象来指定任务之间的排序规则(推荐)。

## 11.15 线程池中的线程如何被销毁的？

# 12. Futrue类

它用于表示一个异步任务的结果，即在执行多线程或异步计算时，`Future`对象可以用于监控任务的状态和获取任务的结果。简单来说，**`Future`表示一个可能在未来某个时刻会返回的计算结果。解决了那些需要返回值的异步调用。**

Futrue类只是一个泛型接口，其中定义了5个方法，主要包括以下四个功能：取消任务；判断任务是否被取消;  判断任务是否已经执行完成;  获取任务执行结果。

## 12.1 Callable和Futrue有什么关系？

我们可以通过 `FutureTask` 来理解 `Callable` 和 `Future` 之间的关系。

`FutureTask` 提供了 `Future` 接口的基本实现，常用来封装`Callable` 和 `Runnable`，具有取消任务、查看任务是否执行完成以及获取任务执行结果的方法。

`ExecutorService.submit()` 方法返回的其实就是 `Future` 的实现类 `FutureTask` 。
`FutureTask` 不光实现了 `Future`接口，还实现了`Runnable` 接口，因此可以作为任务直接被线程执行。

![image.png](%E5%B9%B6%E5%8F%91%20137aa808854d49ceab1550336a1e46f2/image%207.png)

二者关系：一般情况下，会将 `Callable` 任务提交给 `ExecutorService`，并获得一个 `Future` 对象，用于跟踪任务的执行状态和获取任务结果。

---

**定义一个 `Callable` 任务**，该任务是你希望在另一个线程中运行的代码，并且能返回一个结果。

**提交 `Callable` 任务到 `ExecutorService`**，返回一个 `Future` 对象。

---

### 1、Callable 接口

`Callable` 是一个泛型接口，它定义了一个单一的方法 `call()`，返回一个泛型类型的结果。**并可能抛出异常。**

`Callable` 的 `call()` 方法可以返回一个结果。

 `Callable` 通常与 `ExecutorService` 一起使用，提交任务并获取 `Future` 对象。

### 2、Futrue类

`Future` 是一个接口，表示异步计算的结果 。它提供了方法来检查计算是否完成、获取计算结果、取消计算等。
`Future` 的 `get()` 方法用于获取这个结果。

 `Future` 是从 `ExecutorService` 提交任务后返回的对象，用于管理任务的状态和结果。

## 12.2 CompletableFuture

`CompletableFuture` 除了提供了更为好用和强大的 `Future` 特性之外，还提供了函数式编程、**异步任务编排组合（可以将多个异步任务串联起来，组成一个完整的链式调用）等能力。**

### 一个任务需要依赖另外两个任务执行完之后再执行

这种任务编排场景非常适合通过`CompletableFuture`实现。这里假设要实现 T3 在 T2 和 T1 执行完后执行。

通过 `CompletableFuture` 的 `allOf()` 这个静态方法来并行运行 T1 和 T2，当 T1 和 T2 都完成后，再执行 T3。

# 13 虚拟线程

**Java21中才有**

虚拟线程（Virtual Thread）是 JDK 而不是 OS 实现的轻量级线程(Lightweight Process，LWP），由 JVM 调度。许多虚拟线程共享同一个操作系统线程，虚拟线程的数量可以远大于操作系统线程的数量。

## 13.1 优缺点

优点：

- **非常轻量级**：可以在单个线程中创建成百上千个虚拟线程而不会导致过多的线程创建和上下文切换。
- **简化异步编程**： 虚拟线程可以简化异步编程，使代码更易于理解和维护。它可以将异步代码编写得更像同步代码，避免了回调地狱（Callback Hell）。
- **减少资源开销**： 由于虚拟线程是由 JVM 实现的，它能够更高效地利用底层资源，例如 CPU 和内存。虚拟线程的上下文切换比平台线程更轻量，因此能够更好地支持高并发场景。

缺点：

- **不适用于计算密集型任务**： 虚拟线程适用于 I/O 密集型任务，但不适用于计算密集型任务，因为密集型计算始终需要 CPU 资源作为支持。
- **与某些第三方库不兼容**： 虽然虚拟线程设计时考虑了与现有代码的兼容性，但某些依赖平台线程特性的第三方库可能不完全兼容虚拟线程。

## 13.2 创建

- 使用 `Thread.startVirtualThread()` 创建
- 使用 `Thread.ofVirtual()` 创建
- 使用 `ThreadFactory` 创建
- 使用 `Executors.newVirtualThreadPerTaskExecutor()`创建

# 14 其他常见问题

## 14.1 多线程执行后是怎么返回结果的？

**1、使用`Future` 和 `Callable` ：**`Callable` 接口和 `Future` 类是 `java.util.concurrent` 包的一部分，用于表示可以从线程获得的结果。

**2、使用 `CompletionService` ：**`CompletionService` 是 `java.util.concurrent` 包的一部分，结合 `Executor` 和 `BlockingQueue`，可以更方便地处理一组异步任务的结果。

3、使用并发数据结构（如BlockingQueue）:可以使用线程安全的队列来收集线程的结果。

**4、自定义回调方法：自定义回调方法，在任务完成时进行通知**

## 14.2 notify() 和 notifyAll()的区别

notify **: 唤醒一个线程，**其他线程依然处于wait等待唤醒状态，如果唤醒的线程结束时没调用notify，其他线程就永远没人去唤醒，只能等待超时，或被中断。

**//notify在源码的注释中说到notify选择唤醒的线程是任意的**

notifyAll **: 所有线程退出wait的状态，**开始竞争锁，但只有一个线程能抢到，这个线程执行完后，其他线程又会有一个幸运儿脱颖而出得到锁。

## **14.3 协程（考过）**

协程（Coroutine）是一种轻量级线程，它允许在执行中暂停并在之后恢复执行，而无需阻塞线程。

与线程相比，**协程是用户态调度，效率更高，因为它不涉及操作系统的内核调度。**

注：虚拟线程可以被认为是Java对协程的一种实现，虽然实现原理与传统协程略有不同，但它实现了高效开发。

### 协程的特点

- 轻量级

与传统线程不同，协程在用户态切换，不依赖内核态的上下文切换，避免了线程创建、销毁和切换的高昂成本。

- **非抢占式调度**

协程的切换由程序员控制，可以通过显式的yield或await来暂停和恢复执行，避免了线程中断问题。

- 异步化编程

协程可以让异步代码写的像同步代码一样。

### 协程与线程的区别（根据协程的特点来答）

- 调度方式（程序/操作系统）
- 阻塞/非阻塞
- 资源占用

### 协程的应用场景

- 高并发服务：处理大量并发请求的服务，例如Web服务、微服务架构
- 异步I/O操作：I/O密集型，因为协程非阻塞
- 云计算等。

## 14.4 Lock接口

Lock接口 是 **Java并发包(java.util.concurrent.locks)** 中提供的一个比内置synchronized关键字更灵活的线程同步机制。它从Java 5开始引入，提供了更丰富的锁操作。

**常用实现类：**

ReentrantLock：可重入锁，最常用的Lock实现

ReentrantReadWriteLock.ReadLock：读锁

ReentrantReadWriteLock.WriteLock：写锁