# 日志

MySQL日志中比较重要的：二进制日志**bin log（归档日志）**、事务日志**redo log(重做日志)**、**undo log(回滚日志)**

![image.png](%E6%97%A5%E5%BF%97%20ef2da9d6cb624721a34810117c83e5ea/image.png)

完整的日志系统：

**1、归属于mysql server, 不管选择什么存储引擎都会存在。**

slow log:设置具体时间，把执行超时的sql记录在日志文件中，**方便优化调整。**

bin log:主要用于**进行数据库之间的主从同步**。

error log:记录数据库进程之间的一些错误信息。

relay log：在slave机器中暂存同步过来的binlog数据。

**2、归属于innodb引擎：其他存储引擎是不包含该日志信息的**

undo log:回滚日志  redo log：前滚日志

# 1 redo log

MySQL实例挂了或宕机了，重启时，InnoDB存储引擎会使用redo log恢复数据，保证数据的**持久性和完整性。**

![image.png](%E6%97%A5%E5%BF%97%20ef2da9d6cb624721a34810117c83e5ea/image%201.png)

 **一般来说redo log是派不上用场的，要是顺序写的过程中发生数据丢失，那就是真的丢了，任何存储介质都不能保证严格不丢失。**

## 1.1 刷盘时机

InnoDB将redo log刷盘有几种情况：

**1、事务提交时，**log buffer里的redo log会被刷新到磁盘（可以通过`innodb_flush_log_at_trx_commit`参数控制）

**2、log buffer 空间不足时**：log buffer 中缓存的 redo log 已经占满了 log buffer 总容量的大约一半左右，就需要把这些日志刷新到磁盘上。

**3、事务日志缓冲区满：InnoDB** 使用一个事务日志缓冲区（**transaction log buffer**）来暂时存储事务的重做日志条目。当缓冲区满时，会触发日志的刷新，将日志写入磁盘。

**4、正常关闭服务器：**MySQL 关闭的时候，redo log 都会刷入到磁盘里去。

**5、 Checkpoint（检查点）：InnoDB** 定期会执行检查点操作，将内存中的脏数据（已修改但尚未写入磁盘的数据）刷新到磁盘，并且会将相应的重做日志一同刷新，以确保数据的一致性。

## 1.2 `innodb_flush_log_at_trx_commit` 参数

0：设置为 0 的时候，表示**每次事务提交时不进行刷盘操作**。这种方式**性能最高**，但是也**最不安全**，因为如果 MySQL 挂了或宕机了，可能会丢失最近 1 秒内的事务。

1：设置为 1 的时候，**表示每次事务提交时都将进行刷盘操作**。这种方式**性能最低**，但是也**最安全，**因为只要事务提交成功，redo log 记录就一定在磁盘里，不会有任何数据丢失。

2：设置为 2 的时候，**表示每次事务提交时都只把 log buffer 里的 redo log 内容写入 page cache（文件系统缓存）**。page cache 是专门用来缓存文件的，这里被缓存的文件就是 redo log 文件。这种方式的**性能和安全性都介于前两者中间。**

此外，**InnoDB存储引擎有一个后台线程，每隔`1` 秒，就会把 `redo log buffer` 中的内容写到文件系统缓存（`page cache`）**，然后调用 `fsync` 刷盘。**也就是说，一个没有提交事务的redo log记录，也可能会刷盘。**因为在事务执行过程中redo log记录是会写入redo log buffer中，这些redo log记录会被后台线程刷盘。

![image.png](%E6%97%A5%E5%BF%97%20ef2da9d6cb624721a34810117c83e5ea/image%202.png)

## 1.3 日志文件组

 InnoDB 存储引擎有 1 个重做日志文件组( redo log Group），「重做日志文件组」由有 2 个 redo log 文件组成，这两个 redo 日志的文件名叫 ：**`ib_logfile0` 和 `ib_logfile1`** 。

硬盘上存储的redo log日志文件不止一个，而是以一个日志文件组的形式出现的，每个的redo日志文件的大小都是一样的。它们采用**环形数组**的形式，**从头开始写，写到末尾又回头循环写**。

![image.png](%E6%97%A5%E5%BF%97%20ef2da9d6cb624721a34810117c83e5ea/image%203.png)

为什么会有redo log刷盘？

数据页大小是16kb，刷盘比较耗时，可能只修改了数据页里几Byte的数据，没必要把完整的数据页刷盘。

**用redo log形式记录修改内容，性能会远远超过刷数据页的方式，这也让数据库的并发能力更强。**

## 1.4 redo log写入和数据写入磁盘的区别

写入 redo log 的方式使用了**追加操作**， 所以磁盘操作是**顺序写**，而写入数据需要先找到写入位置，然后才写到磁盘，所以磁盘操作是**随机写**。

磁盘的「顺序写 」比「随机写」 高效的多，**因此 redo log 写入磁盘的开销更小**。

## 1.5 redo log怎么保证持久性？

**1、Write - ahead logging (WAL，预写式日志) ：在事务提交之前，将事务所做的修改操作记录到redo log中，然后再将数据写入磁盘**。

这样即使在数据写入磁盘之前发生了宕机，系统可以通过redo log中的记录来恢复数据。

---

WAL核心思想是：在对数据库进行任何数据**修改操作之前**，**先将这些修改操作的记录写入日志文件中。**

WAL减少了对数据文件的直接写入操作。因为日志文件是顺序写入的，而数据文件的写入通常是随机的，顺序写入的性能通常比随机写入高得多。因此，使用WAL可以提高数据库的整体性能。

---

**2、Redo log的顺序写入** ： redo log采用追加写入的方式，将redo日志记录追加到文件末尾，而不是随机写入，这样可以减少磁盘的 随机I/O 操作，提高写入性能。

**3、Checkpoint机制：**MySQL会定期将内存中的数据刷新到磁盘，同时将最新的 LSN（Log Sequence Number）记录到磁盘中，这个 LSN 可以确保 redo log中的操作是按顺序执行的。在恢复数据时，系统会根据LSN来确定从哪个位置开始应用redo log

## 1.6 MySQL插入一条SQL语句，redo log记录的是什么？

redo log是物理日志，记录**“某页（Page）某位置的数据被修改为某值”**。

它不记录逻辑操作（如“插入一行”），而是直接记录对页的变更，所以在插入操作中，redo log记录的是事务在数据页上的修改，**数据页的插入点、记录的偏移量和插入的实际数据并更新页目录、页头等**元数据。

## **1.7 具体是怎么刷盘的（MySQL的页大小和磁盘里的页大小是不一致的）**

### **核心问题：**

**1、页大小不一致** InnoDB页大小 ：16KB \磁盘物理页大小：4KB

**2、原子性问题** 写入 16KB 的 InnoDB 页需要操作 4 个连续的 4KB 磁盘页，若写入过程中系统崩溃，可能导致 **部分写（Partial Write） 问题（仅部分磁盘页被更新）**

### **刷脏页的核心流程：**

**1、脏页的标记与组织**

每个数据页在缓冲池（Buffer Pool）中被修改后标记为脏页，脏页通过 **Flush List 链表**按修改时间**（LSN, Log Sequence Number）排序**

**2、写入Doublewrite Buffer(解决部分写问题)**

Step1、顺序写入：将16KB的脏页按顺序写入 Doublewrite Buffer（磁盘上的连续物理区域）

Doublewrite Buffer分两部分：**共享表空间的 Doublewrite 段**（系统表空间内）**独立文件的 Doublewrite 文件**（MySQL 8.0+）

Step2、离散写入

再将脏页写入实际的数据文件位置（可能非连续磁盘区域）**其实就是多了一步缓冲的东西**

**3、解决页大小不匹配问题**

**写入粒度适配**：每个 16KB InnoDB 页被拆分为 4 个连续的 4KB 磁盘页写入

**Doublewrite 的作用 ：**1、若数据文件写入中途崩溃，恢复时可通过 Doublewrite Buffer 中的完整副本来修复损坏的页2、确保 16KB 的原子性写入（即使底层磁盘页是 4KB）

**Doublewrite满了（到2MB时）就写**

# 2. bin log

redo log 是物理日志，记录内容是**“在某个数据页上做了什么修改”**，属于 InnoDB 存储引擎。

binlog 是逻辑日志，记录内容是语句的原始逻辑，类似于 **“给 ID=2 这一行的 c 字段加 1”** ，**属于`MySQL Server` 层。**所有存储引擎都可以使用。**主要用了进行数据库之间的主从同步。**

bin log可以 **同步数据，保证数据的一致性**，MySQL的数据备份，**主从复制离不开bin log。**

![image.png](%E6%97%A5%E5%BF%97%20ef2da9d6cb624721a34810117c83e5ea/image%204.png)

### binlog的格式

**STATEMENT ：** 记录实际执行的SQL语句，日志量小，但可能因函数/触发器 导致主从不一致（如NOW（））。

**ROW ：**记录每行数据的变更细节**（默认格式）**日志量大，但主从一致性强，适合高精度复制。

**MIXED ：**节省空间，同时兼顾了一定的一致性。

### binlog的用处

主从同步\数据恢复\**数据同步工具：canal**

数据同步工具，可以捕获binlog，看binlog里面发生了什么变更。

## 2.1 写入机制

bin log 的写入时机也非常简单，事务执行过程中，**先把日志写到`binlog cache`，事务提交的时候，再把`binlog cache`写到 bin log 文件中（记录了所有数据库表结构变更和表数据修改的日志，不会记录查询类的操作）。**binlog是追加写，写满一个文件，就创建一个新的文件继续写，不会覆盖以前的日志。

刷盘流程：

![image.png](%E6%97%A5%E5%BF%97%20ef2da9d6cb624721a34810117c83e5ea/image%205.png)

write:把日志写入到文件系统的page cache，并没有把数据持久化到磁盘，所以速度比较快

fsync将数据持久化到磁盘

**MySQL 集群的主从复制过程** 梳理成 3 个阶段：

- **写入 Binlog**：主库写 binlog 日志，提交事务，并更新本地存储数据。
- **同步 Binlog**：把 binlog 复制到所有从库上，每个从库把 binlog 写到暂存日志中。
- **回放 Binlog**：回放 binlog，并更新存储引擎中的数据。

总结：主从复制依赖于binlog，复制的过程就是将binlog中的数据从主库传输到从库上，这个过程一般是异步的。在完成主从复制之后，你就可以在写数据时只写从库，在读数据时只读从库，这样即使写请求会锁表或者锁记录，也不会影响请求的执行。

## 2.2 两阶段提交 (重要)

redo log(重做日志)，让  InnoDB 存储引擎拥有了崩溃恢复能力。bin log(归档日志)，保证了MySQL集群架构的数据一致性。

在执行更新语句过程中，会记录redo log和bin log两块日志，以基本的事务为单位，redo log在事务执行过程中可以不断写入，**而bin log只有在提交事务时才写入，所以 redo log 和 bin log 的写入时机不一样。**

![image.png](%E6%97%A5%E5%BF%97%20ef2da9d6cb624721a34810117c83e5ea/image%206.png)

**为了解决两份日志之间的逻辑一致问题**，InnoDB存储引擎使用**两阶段提交**方案。

将redo log的写入拆成了两个步骤：prepare 和 commit。

![image.png](%E6%97%A5%E5%BF%97%20ef2da9d6cb624721a34810117c83e5ea/image%207.png)

### 两阶段提交有什么问题？

两阶段提交虽然保证了两个日志文件的数据一致性，但是性能很差。

1、**磁盘 I/O 次数高**：对于“双1”配置，每个事务提交都会进行两次 fsync（刷盘），一次是 redo log 刷盘，另一次是 bin log 刷盘。

2、**锁竞争激烈**：两阶段提交虽然能够保证「单事务」两个日志的内容一致，但在「多事务」的情况下，却不能保证两者的提交顺序一致，因此，在两阶段提交的流程基础上，还需要加一个锁来保证提交的原子性，从而保证多事务的情况下，两个日志的提交顺序一致。

---

## 改进：组提交

**MySQL 引入了 binlog 组提交（group commit）机制，当有多个事务提交的时候，会将多个 binlog 刷盘操作合并成一个，从而减少磁盘 I/O 的次数。**

引入了组提交机制后，prepare 阶段不变，只针对 commit 阶段，将 commit 阶段拆分为三个过程：

**flush 阶段**：多个事务按进入的顺序将 binlog 从 cache 写入文件（不刷盘）
**sync 阶段**：对 binlog 文件做 fsync 操作（多个事务的 binlog 合并一次刷盘）
**commit 阶段**：各个事务按顺序做 InnoDB commit 操作；

---

## 2.3 bin log什么时候刷盘

事务执行过程中，先把日志写到 bin log cache（Server 层的 cache），**事务提交的时候，**再把 **bin log cache 写到 bin log 文件中。**

## **2.4 redo log和bin log的区别**

- bin log是逻辑日志，记录写操作的sql；redo log是数据页变动情况，物理日志，记录的是一些二进制数据。
- bin log会不断累积，redo log会循环利用文件组覆盖。
- bin log的目的是记录所有的写SQL,用于归档，可以恢复到任意时间，**redo log的目的是故障恢复，只需要保证记录所有的脏页即可。**

### bin log为什么不能用来做故障恢复？

因为故障恢复本身是要把产生线上影响的数据恢复回来，这是**mysql先内存后异步刷盘导致的问题**，如果写内存后，没有刷盘就崩溃了，此时需要将写入内存的脏页恢复到磁盘上，这是因为脏页虽然在内存中，但是可能已经提供服务出去了，因而故障恢复本质就是脏页的恢复。

redo log**能保证事务提交时就已经刷盘到日志文件**，专门用来恢复脏页，**而binlog不能做这个保证**，并且记录的是全量的写sql日志，如果用其做故障恢复，要全量删库然后运行binlog,过于兴师动众。

# 3. undo log

**每一个事务对数据的修改都会被记录到 undo log** ，当执行事务过程中出现错误或者需要执行回滚操作的话，MySQL 可以利用 undo log 将数据恢复到事务开始之前的状态。

怎么恢复？其实就是做**反向操作**，插入的删除，删除的插入，新值更新为旧值。

## redo log与undo log?

这两种日志是属于 InnoDB 存储引擎的日志，它们的区别在于：
• redo log 记录了此次事务「**完成后**」的数据状态，记录的是更新**之后**的值；
• undo log 记录了此次事务「**开始前**」的数据状态，记录的是更新**之前**的值；

---

# 4.总结：执行一条更新语句的流程：`UPDATE t_user SET name = 'xiaolin' WHERE id = 1;`

step1、执行器负责具体执行，会调用存储引擎的接口，通过主键索引树搜索获取 id = 1 这一行记录（是否在BufferPool中）

step2、执行器得到聚簇索引记录后，会看一下更新前的记录和更新后的记录是否一样**（一样就算了）**

step3、开启事务， InnoDB 层更新记录前，首先要记录相应的 undo log，因为这是更新操作，需要把被更新的列的旧值记下来，也就是要生成一条 undo log，undo log 会写入 Buffer Pool 中的 Undo 页面，**不过在内存修改该 Undo 页面后，需要记录对应的 redo log。**

step4、InnoDB 层开始更新记录，会**先更新内存（同时标记为脏页）**，然后将记录写到 redo log 里面，这个时候更新就算完成了。为了减少磁盘I/O，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘。这就是 **WAL 技术**，**MySQL 的写操作并不是立刻写到磁盘上，而是先写 redo 日志，然后在合适的时间再将修改的行数据写到磁盘上。**

step5、在一条更新语句执行完成后，**然后开始记录该语句对应的 binlog，时记录的 binlog 会被保存到 binlog cache，并没有刷新到硬盘上的 binlog 文件，在事务提交时才会统一将该事务运行过程中的所有 binlog 刷新到硬盘。**

step6、事务提交（两阶段提交）

# 5. Canal 数据同步

Canal组件是一个基于**MySQL数据库增量日志解析**，提供增量数据订阅和消费，支持将增量数据投递到下游消费者（如Kafka、RocketMQ等）或者存储（ElasticSearch、HBase等）的组件。

↑ Canal感知MySQL数据的变动，然后解析变动数据，将变动数据发送到MQ或者同步到其他数据库。

## 5.1 Canal 的工作原理

- **MySQL 的主从复制原理**

MySQL master 将数据变更写入二进制日志binlog → MySQL slave将master的binlog拷贝到它的中继日志 relay log → MySQL slave重放relay log操作，将变更数据同步到最新。

- **Canal工作原理**

1、Canal 将自己伪装为MySQL slave(从库)，向MySQL master（主库）发送dump协议

![image.png](%E6%97%A5%E5%BF%97%20ef2da9d6cb624721a34810117c83e5ea/image%208.png)

2、MySQL master(主库)收到dump请求，开始推送bin log给slave(即canal)

3、**Canal接收并解析Binlog日志**，得到变更的数据，执行后续逻辑

## 5.2 Canal运用场景

**1、数据同步**

Canal可以帮助用户进行多种数据同步操作，如实时同步MySQL数据到ElasticSearch、Redis等数据存储介质中。

![image.png](%E6%97%A5%E5%BF%97%20ef2da9d6cb624721a34810117c83e5ea/image%209.png)

**2、数据库实时监控**

Canal可以实时监控MySQL的更新操作，对于敏感数据的修改可以及时通知相关人员。

![image.png](%E6%97%A5%E5%BF%97%20ef2da9d6cb624721a34810117c83e5ea/image%2010.png)

**3、数据分析和挖掘**

Canal可以将MySQL增量数据投递到Kafka等消息队列中，为数据分析和挖掘提供数据来源

**4、数据库备份、迁移**

Canal可以将MySQL主库上的数据增量日志复制到备库上，实现数据库备份

## 5.3 Canal的使用

1、配置修改：修改canal.properties的配置 → 修改实例配置文件instance.properties

2、导入相关依赖

3、相关代码

![image.png](%E6%97%A5%E5%BF%97%20ef2da9d6cb624721a34810117c83e5ea/image%2011.png)

Messagge ：一次Canal从日志中抓取的信息，一个Message可以包含多个SQL执行结果。

Entry ：表示一个SQL指令执行后，改动数据，将这些数据封装到Entry中。

## 5.4 Canal优缺点

优点：高性能、分布式、可靠性好、支持数据过滤和转换。

缺点：不支持数据的回溯（无法获取历史数据）。