# Redis

# 1 基本概念

Redis 是一个**基于C语言**开发的 **开源NoSQL数据库**， 与传统数据库不同，Redis的数据是 **保存在内存中** 的(内存数据库，支持持久化)，**因此读写速度非常快（读写操作都是基于内存的）**，被广泛应用于**分布式缓存方向**。

对数据类型的操作都是**原子性的，** 因为执行命令是由**单线程**负责的，**不存在并发竞争问题。**

## 1.1 为什么使用Redis，Redis有什么有优点？

这个问题比较综合，更多的是考察Redis的整体特性。**可以按学习过的章节来回答。**

如果问到Redis为什么这么快的话，除了内存操作、单线程模型、持久化机制。还要考虑到**数据结构**

还有**高效的I/O多路复用（如epoll在Linux系统上，允许Redis在单个线程中同时监听多个套接字，并在有数据到达时进行处理，从而极大地提高了并发处理能力。）**

### 哪些场景下比较适合用Redis?

- **极端高性能要求的实时场景**

存读写速度（微秒级）远超磁盘数据库（毫秒级），无法替代

- **复杂数据结构的原子操作**

Redis 提供 `Set`/`ZSet` 等结构的原子操作，传统数据库难以高效实现。

- **大规模分布式系统协调**

Redis 的原子性和单线程模型简化了分布式协调逻辑，避免竞态条件。

### 高性能与高并发

Redis 是一种**内存数据库，** 所有 **数据都存储在内存中，因此读写操作速度非常快**，通常能达到毫秒级的延迟。这使得 Redis 特别适用于需要快速响应时间的应用场景，如缓存、实时数据处理等。

单台设备的Redis的 **QPS(Query Per Second，每秒处理完请求的次数)** 是MySQL的10倍。（高并发）

### **丰富的数据结构**

Redis 支持多种高级数据结构，如 **字符串、列表、集合、有序集合（Zset）、哈希表（Hash）** 等。这些数据结构使得 Redis 能够高效地处理复杂的数据操作。

此外，还有Bitmaps（位图）、HyperLogLog（基数统计）、GEO(地理信息)等。

### **持久化机制**

Redis 提供了 **RDB（Redis Database）** 快照和 **AOF（Append-Only File）** 日志两种持久化机制。RDB 会定期保存内存数据的快照，而 AOF 则记录每一个写操作。通过持久化机制，**Redis 可以在重启后恢复数据。**

### **主从复制**

Redis 支持主从复制（master-slave replication），可以将数据从一个 Redis 实例复制到多个只读副本中，从而实现负载均衡和高可用性。

### **集群模式**

**Redis Cluster 提供了分布式集群功能，允许数据分布在多个节点上，从而实现数据的分片和负载均衡。这使 得 Redis 能够处理更大规模的数据集。**

## 1.2 Redis和Memcached

**共同点：都是基于内存的数据库，一般都是当作缓存来使用**

**不同：**

1、Redis支持的数据类型更加丰富，而Memcached只支持最简单的key-value数据类型

2、Redis**支持数据的持久化**，可将内存中的数据保存在磁盘中，Memcached没有持久化功能，数据全部存在内存中

3、Redis**支持集群等功能**

# 2 Redis数据结构

![image.png](Redis%20b578709820504e55b16b475594664497/image.png)

## 2.1 字符串

String 类型的底层的数据结构实现主要是 **SDS（Simple Dynamic Strings，简单动态字符串）**

![image.png](Redis%20b578709820504e55b16b475594664497/image%201.png)

**1、SDS 不仅可以保存文本数据，还可以保存二进制数据**。 （二进制安全）因为SDS不需要“\0”字符来标识字符串结尾了，而是有个专门的len成员变量来记录长度，**所以可存储包含“\0”的数据，但是SDS为了兼容部分C语言标准库的函数，SDS字符串结尾还是会加上“\0”字符**。

2、**SDS 获取字符串长度的时间复杂度是 O(1)**。**SDS结构加入了len成员变量，那么获取字符串长度的时候，直接返回这个成员变量的值就行，所以复杂度只有O(1)。**

**3、Redis 的 SDS API 是安全的，拼接字符串不会造成缓冲区溢出。当判断缓冲区大小不够用时，Redis会自动扩大SDS的空间大小。**

### 应用场景

**1、缓存对象：使用 String 来缓存对象有两种方式：直接缓存整个对象的 JSON，采用将 key 进行分离为 user:ID:属性**

**2、分布式锁**

**3、共享 Session 信息**

## 2.2 List

List 类型的底层数据结构是由**双向链表或压缩列表**实现的。

1、如果列表的元素个数**小于 512 个**（默认值，可由 list-max-ziplist-entries 配置），列表每个元素的值都**小于 64 字节**（默认值，可由 list-max-ziplist-value 配置）Redis 会使用**压缩列表**作为 List 类型的底层数据结构；

2、如果列表的元素不满足上面的条件，Redis 会使用**双向链表**作为 List 类型的底层数据结构；

**在 Redis 3.2 版本之后，List 数据类型底层数据结构就只由  quicklist 实现了，替代了双向链表和压缩列表**。

### 应用场景

**消息队列**

**List 不支持多个消费者消费同一条消息**， **List 类型并不支持消费组的实现**。

## 2.3 Hash

**Hash类型的底层数据结构是由压缩列表或哈希表**实现的
1、压缩链表同上面一样，如果哈希类型元素个数 **小于 512 个**（默认值，可由 hash-max-ziplist-entries 配置），所有值 **小于 64 字节**（默认值，可由 hash-max-ziplist-value 配置）的话，Redis 会使用**压缩列表**作为 Hash 类型的底层数据结构；

2、如果哈希类型元素不满足上面条件，Redis 会使用**哈希表作为 Hash 类型的底层数据结构。**

**在 Redis 7.0 中，压缩列表数据结构已经废弃了，交由 listpack 数据结构来实现了**。

### 应用场景

**缓存对象**

Hash 类型的 （key，field， value）的结构与对象的（对象id， 属性， 值）的结构相似，也可以用来存储对象。

## 2.4 Set类型

Set 类型的底层数据结构是由**哈希表或整数集合**实现的

如果集合中的元素都是整数且元素个数**小于 512** （默认值，set-maxintset-entries配置）个，Redis 会使用**整数集合**作为 Set 类型的底层数据结构。
如果集合中的元素不满足上面条件，则 Redis 使用**哈希表**作为 Set 类型的底层数据结构。

## 2.5 ZSet

ZSet 类型的底层数据结构是由 **压缩列表或跳表** 实现的（其实是跳表+Set）：

如果 **有序集合** 的元素个数小于 128 个，并且每个元素的值小于 64 字节时，Redis 会使用**压缩列表**作为 Zset 类型的底层数据结构；
如果有序集合的元素不满足上面的条件，Redis 会使用**跳表作为 Zset 类型的底层数据结构；**

### 应用场景：排行榜（考过）

有序集合不仅能够存储唯一元素，还可以为每个元素关联一个分数（score），并根据分数对元素进行排序。 

**Zset设计** 

**Key设计→ 业务名：对象名：排行维度** 

**Value结构 → 成员member 分数score排序依据的数值。**

---

扩展问题：如果要获取排行榜前10000名要怎么办？考虑大key对其产生影响？

1、**使用 `ZREVRANGE` 命令**

```sql
ZREVRANGE leaderboard 0 9999 WITHSCORES
```

2、**分页获取**

为了避免一次性获取大量数据导致的性能问题，可以采用分页的方式逐步获取数据。例如，每次获取 1,000 名玩家，分 10 次获取 10,000 名玩家

```sql
# 获取前1000名
ZREVRANGE leaderboard 0 999 WITHSCORES

# 获取1001-2000名
ZREVRANGE leaderboard 1000 1999 WITHSCORES

# 以此类推
```

---

### 向ZSet中插入数据的过程是怎么样的？

**Step1、查找插入位置。从最高层开始**，从左到右遍历跳跃表，找到每一层中最后一个小于目标分值（score）的节点。记录每一层的插入位置（即每一层中最后一个小于目标分值的节点）。

**Step2、随机生成层数。** 为新节点随机生成一个层数（level）。层数的生成遵循一定的概率分布（例如，每增加一层的概率为 50%）

**Step3、创建新节点：** 根据生成的层数，创建一个新的跳跃表节点。

**Step4、更新指针：** 将新节点插入到每一层的链表中。更新每一层的跨度。

**Step5、更新跳跃表的状态：** 如果新节点的层数高于当前跳跃表的最高层数，则更新跳跃表的最高层数。更新跳跃表的长度。

**跳跃表的插入操作平均时间复杂度为O（logN），适合高效的存储和操作有序数组。**

## 2.6 Redis大key会有什么问题？

大 key 会带来以下四种影响：

**1、客户端超时阻塞**。由于 Redis 执行命令是单线程处理，然后在操作大 key 时会比较耗时，那么就会阻塞 Redis，从客户端这一视角看，就是很久很久都没有响应。

**2、引发网络阻塞**。每次获取大 key 产生的网络流量较大，如果一个 key 的大小是 1 MB，每秒访问量为 1000，那么每秒会产生 1000MB 的流量，这对于普通千兆网卡的服务器来说是灾难性的。

**3、阻塞工作线程**。如果使用 del 删除大 key 时，会阻塞工作线程，这样就没办法处理后续的命令。

**4、内存分布不均**。集群模型在 slot 分片均匀情况下，会出现数据和查询倾斜情况，部分有大 key 的 Redis 节点占用内存多，QPS 也会比较小。 

---

解决方法：
- **1、拆分成多个小key。** 这是最容易想到的办法，降低单key的大小，读取可以用mget批量读取。
- **2、设置合理的过期时间。** 为每个key设置过期时间，并设置合理的过期时间，以便在数据失效后自动清理，避免长时间累积的大Key问题。
- **3、启用内存淘汰策略。** 启用Redis的内存淘汰策略，例如LRU（Least Recently Used，最近最少使用），以便在内存不足时自动淘汰最近最少使用的数据，**防止大Key长时间占用内存。**
- **4、数据分片。** 例如使用Redis Cluster将数据分散到多个Redis实例，以减轻单个实例的负担，降低大Key问题的风险。
- **5、使用UNLINK命令删除大key（删除大key的指令）**，UNLINK命令是DEL命令的异步版本，它可以在后台删除Key，避免阻塞Redis实例。

## 2.7 Redis 3种特殊数据类型详解

### 2.7.1 Bitmap 位图

**Bitmap 存储的是连续的二进制数字（0 和 1），** 通过 Bitmap, 只需要一个 bit 位来表示某个元素对应的值或者状态，key 就是对应元素本身 。我们知道 8 个 bit 可以组成一个 byte，所以 Bitmap 本身会极大的节省储存空间。

可以将Bitmap看作是一个存储二进制数字（0和1）的数组，数组中每个元素的下标叫做offset（偏移量）

应用场景：**用户行为统计（是否点赞过某个视频）**

### 2.7.2 HyperLogLog 基数统计

HyperLogLog 是一种有名的基数计数概率算法 ，基于 LogLog Counting(LLC)优化改进得来，并不是 Redis 特有的，Redis 只是实现了这个算法并提供了一些开箱即用的 API。

**主要用于高效的估计一个集合中唯一元素的数量（即基数）**

**占用空间非常非常小，** 只需要12K的空间就能存储接近2^64个不同元素。**存在一定误差。**

应用场景：**数量巨大（百万、千万级别以上）的计数场景（热门帖子uv统计）**

### 2.7.3 Geospatial 地理位置

Geospatial index（地理空间索引，简称 GEO） 主要用于存储地理位置信息，基于 Sorted Set 实现。

通过 GEO 我们可以轻松实现两个位置距离的计算、获取指定位置附近的元素等功能。

GEO底层是Sorted Set，可以对GEO使用Sorted Set指令。

## 2.8 Redis有序集合底层为什么要使用跳表？

有序集合 **（ Sorted Set,简称ZSet )** 保证元素有序且唯一的集合。

因为设计者考虑到 Redis 数据存放于内存，为了节约宝贵的内存空间在有序**集合在元素小于 64 字节且个数小于 128 的**时候，会使用 **ziplist(压缩列表 )**，而这个阈值的默认值的设置就来自下面这两个配置项。

```bash
zset-max-ziplist-value 64
zset-max-ziplist-entries 128
```

一旦有序集合中的某个元素超出这两个其中的一个阈值它就会转为 **skiplist（跳表）**（实际是 dict+skiplist，还会借用字典来提高获取指定元素的效率）。

### 跳表

**跳表我们完全可以理解为在原始链表基础上，建立多级索引，通过多级索引检索定位将增删改查的时间复杂度变为O(log n)**。

![image.png](Redis%20b578709820504e55b16b475594664497/image%202.png)

**每级索引的索引个数都是基于下层元素个数的一半**。就好像变成了**二分查找**一样。设计跳表时，尽可能保证每一个上级索引都是下级索引的一半。

**设计：**

1、跳表的高度计算从原始链表开始，即默认情况下插入的元素的高度为 1，代表没有索引，只有元素节点。

2、设计一个为插入元素生成节点索引高度 level 的方法。

3、进行一次**随机运算**，随机数值范围为 0-1 之间。

4、如果随机数大于 0.5 则为当前元素添加一级索引，自此我们保证生成一级索引的概率为**50%**，这也就保证了 1 级索引理想情况下只有一半的元素会生成索引。

5、同理后续每次随机算法得到的值大于 0.5 时，我们的索引高度就加 1，这样就可以保证节点生成的 2 级索引概率为**25%**，3 级索引为**12.5%**……**（设置层高）**

**//Redis跳表在创建节点的时候，随机生成每个节点的层数，并没有严格维持相邻两层的节点数量比例为2：1的情况。**

**跳表与其他数据结构比较**

1、平衡树：平衡树我们又会称之为 **AVL 树**，是一个严格的平衡二叉树，平衡条件必须满足（所有节点的左右子树高度差不超过 1，即平衡因子为范围为 `[-1,1]`）。平衡树的插入、删除和查询的时间复杂度和跳表一样都是 **O(log n)**。

但是它的每一次插入或者删除操作都需要保证整颗树左右节点的绝对平衡，**只要不平衡就要通过旋转操作来保持平衡，这个过程是比较耗时的。**

2、红黑树：红黑树（Red Black Tree）也是一种自平衡二叉查找树，它的查询性能略微逊色于 AVL 树，但插入和删除效率更高。红黑树的插入、删除和查询的时间复杂度和跳表一样都是 **O(log n)**。

相比较于红黑树来说，**跳表的实现也更简单一些**。并且，**按照区间来查找数据这个操作，红黑树的效率没有跳表高。**

3、B+树:B+树更适合作为数据库和文件系统中常用的索引结构之一，它的核心思想是通过可能少的 IO 定位到尽可能多的索引来获得查询数据。

对于 Redis 这种内存数据库来说，它对这些并不感冒，因为 Redis 作为内存数据库它不可能存储大量的数据，所以对于索引不需要通过 B+树这种方式进行维护，只需按照概率进行随机维护即可，**节约内存。**

而且**使用跳表实现 zset 时相较前者来说更简单一些**，在进行插入时只需通过索引将数据插入到链表中合适的位置再随机维护一定高度的索引即可，也不需要像 B+树那样插入时发现失衡时还需要对节点分裂与合并。

### 压缩列表

压缩列表是Redis**为了节约内存**而开发的，它是由**连续内存块组成**的顺序型数据结构。有点类似于数组

![image.png](Redis%20b578709820504e55b16b475594664497/image%203.png)

zlbytes ：记录整个压缩列表占用对内存字节数。

zltail :  记录压缩列表【尾部】节点距离起始地址多少字节，也就是列表尾的偏移量。

zllen : 标记压缩列表包含的节点数量。

zlend : 标记压缩列表的结束点，固定值为 0xFF 。

**压缩链表**中，**如果我们要查找定位第一个元素和最后一个元素，可以通过表头三个字段（zlen）的长度直接定位，复杂度是O（1）。** 而查找其他元素时，就没这么高效了，只能逐个查找，此时的复杂度就是O（n）了。

![image.png](Redis%20b578709820504e55b16b475594664497/image%204.png)

prev len : 记录【前一个节点】的长度，目的是为了实现从后向前遍历。

encoding:记录了当前节点数据实际数据的【类型和长度】，类型主要有两种：字符串和整数。

data:记录了当前节点的实际数据，类型和长度都有encoding决定。

 **怎么节约内存？** 根据数据大小和类型进行不同的空间大小分配的设计思想。但是，连锁更新一旦发生就会导致压缩链表占用的内存空间要多次重新分配，就会**直接影响到压缩列表的访问性能，所以压缩列表只会用于保存节点数量不多的场景。**

### quick list

quick list 虽然通过控制 quicklistNode 结构里的压缩列表的大小或者元素个数，来减少连锁更新带来的性能影响，但是并没有完全解决连锁更新的问题。

### list pack

![image.png](Redis%20b578709820504e55b16b475594664497/image%205.png)

list pack头包含两个属性，分别记录了 list pack 总字节数和元素数量，然后 list pack 末尾也有个结尾标识，图中的 list pack entry就是 list pack 的节点了。

每个list pack节点结构如下：

![image.png](Redis%20b578709820504e55b16b475594664497/image%206.png)

encoding : 定义该元素的编码类型，会对不同的整数和字符串进行编码。

data : 实际存放的数据。

len : encoding + data 的总长度。

**list pack 没有压缩列表中记录前一个节点长度的字段了。list pack只记录当前节点的长度，当我们向list pack加入一个新元素的时候，不会影响其他节点的长度字段的变化，从而避免压缩列表的连锁更新问题。**

## 2.8 Redis的某个key的value是1，那么底层数据是什么?

- 当使用**SET mykey 1**这样的命令直接设置数字值时：Redis会**直接将数字1以64位有符号整数的形式存储。** 不是字符串，而是直接在redisObject的ptr字段中存储整数值。
- 当使用SET mykey "1"明确设置为字符串时，使用嵌入式简单动态字符串（embedded SDS）

Redis的这种智能编码选择是其高性能和内存效率的重要原因，开发者无需关心底层细节，Redis会自动选择最优的存储方式。

# 3. Redis持久化

为了保证内存中的数据不会丢失，Redis 实现了数据持久化的机制，这个机制会把数据存储到磁盘，这样在 Redis 重启就能够从磁盘中恢复原有的数据。

Redis持久化一共有三种方式：

**AOF 日志**：每执行一条写操作命令，就把该**命令以追加的方式写入到一个文件**里；

**RDB 快照**：将**某一时刻**的内存数据，以**二进制的方式**写入磁盘；                                            

**混合持久化方式**：Redis 4.0 新增的方式，集成了 AOF 和 RBD 的优点；

### RDB和AOF分别适用于什么场景？

RDB适合**需要完整数据备份的场景**，单个RDB文件包含某一时刻的全部数据，便于迁移和恢复。**大数据量快速恢复，** 恢复大数据集时比AOF更快。

AOF适用于**小数据量频繁写入**，对写入性能影响较小。需要完整的操作记录，**适合需要审计或重放所有写操作的场景。**

## 3.1 AOF 持久化

Redis 在执行完一条写操作命令后，就会把该命令以**追加的方式**写入到一个文件里，**（先写指令，再记录日志）** 然后 Redis 重启时，会读取该文件记录的命令，然后逐一执行命令的方式来进行数据恢复。

![image.png](Redis%20b578709820504e55b16b475594664497/image%207.png)

### AOF的写回策略

Redis 写入 AOF 日志的过程，Redis 提供了 3 种写回硬盘的策略，

在 Redis.conf 配置文件中的 appendfsync 配置项中，可以填入：

**1、Always**「总是」，每次写操作命令执行完后，同步将 AOF 日志数据写回硬盘。

2、**Everysec：每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，然后每隔一秒将缓冲区里的内容写回到硬盘。**

3、**No：不由Redis决定，而是由操作系统来决定。先将命令写入到 AOF 文件的内核缓冲区，再由操作系统决定何时将缓冲区内容写回硬盘。** No不是不写，而是由操作系统去写。

![image.png](Redis%20b578709820504e55b16b475594664497/image%208.png)

### AOF过大，会触发重写

在重写时，读取当前数据库中的所有键值对，将每一个键值对用一条命令记录到「新的 AOF 文件」，等到全部记录完后，就将新的 AOF 文件替换掉现有的 AOF 文件。

**重写 AOF 过程是由后台子进程 *bgrewriteaof* 来完成的。**

子进程进行 AOF 重写期间，主进程可以继续处理命令请求，从而避免阻塞主进程；

子进程带有主进程的数据副本，这里使用子进程而不是线程，因为如果是使用线程，多线程之间会共享内存，那么在修改共享内存数据的时候，需要通过加锁来保证数据的安全，而这样就会降低性能。而使用子进程，创建子进程时，父子进程是共享内存数据的，不过这个共享的内存只能以只读的方式。

**重写过程中，主进程依然可以正常处理命令**，重写 AOF 日志过程中，如果主进程修改了已经存在 key-value，Redis 设置了一个 **AOF 重写缓冲区**，这个缓冲区在 **创建 bgrewriteaof 子进程之后开始使用。**
当 Redis 执行完一个写命令,它会**同时将这个写命令写入到 「AOF 缓冲区」和 「AOF 重写缓冲区」**。

![image.png](Redis%20b578709820504e55b16b475594664497/image%209.png)

## 3.2 RDB快照

RDB 快照就是记录某一个瞬间的内存数据， Redis 恢复数据时， **RDB 恢复数据的效率会比 AOF 高些**。**因为直接将 RDB 文件读入内存就可以，不需要像 AOF 那样还需要额外执行操作命令。**

### Redis 提供了两个命令来生成 RDB 文件

执行了 **save 命令，** 就会在主线程生成 RDB 文件，由于和执行操作命令在同一个线程，所以如果写入 RDB 文件的时间太长，**会阻塞主线程。**

执行了 **bgsave 命令，** 会创建一个子进程来生成 RDB 文件，这样可以 **避免主线程的阻塞。**

关于bgsave命令：执行 bgsave 过程中，Redis 依然**可以继续处理操作命令**的，数据是能被修改的，关键的技术就在于**写时复制技术（Copy-On-Write, COW）。写时复制，Java中也有对于的数据结构。**

执行 bgsave 命令的时候，会通过 fork() 创建子进程，此时 **子进程和父进程是共享同一片内存数据**的，**因为创建子进程的时候，会复制父进程的页表。** 但是页表指向的物理内存还是一个，此时如果主线程执行读操作，则主线程和 bgsave 子进程互相不影响。

![image.png](Redis%20b578709820504e55b16b475594664497/image%2010.png)

**如果主线程执行写操作，则被修改的数据会复制一份副本，** 然后 **bgsave 子进程会把该副本数据写入 RDB 文件，在这个过程中，主线程仍然可以直接修改原来的数据。**

# 4. Redis 缓存设计

## 4.1 如何避免缓存雪崩、缓存穿透、缓存击穿？

击穿，是缓存中原来存在；（击穿，这个动词，一定是先有什么东西，**先击后穿**）

穿透，是缓存中根本就没有的东西。

### 缓存雪崩

为了保证缓存中的数据与数据库中的数据一致性，会给 Redis 里的数据设置过期时间，当缓存数据过期后，用户访问的数据如果不在缓存里，业务系统需要重新生成缓存，因此就会访问数据库。

**大量缓存数据在同一时间过期（失效）时，如果此时有大量的用户请求，都无法在 Redis 中处理，于是全部请求都直接访问数据库，从而导致数据库的压力骤增，严重的会造成数据库宕机，从而形成一系列连锁反应，造成整个系统崩溃，这就是缓存雪崩。**

### 缓存雪崩的解决方法

可能发生雪崩的两个原因：

• 原因一：大量数据同时过期。解决方式：

1、**均匀设置过期时间**：如果要给缓存数据设置过期时间，应该避免将大量的数据设置成同一个过期时间。我们可以在对缓存数据设置过期时间时，**给这些数据的过期时间加上一个随机数**，这样就保证数据不会在同一时间过期。

2、**互斥锁**：当业务线程在处理用户请求时，**如果发现访问的数据不在 Redis 里，就加个互斥锁，保证同一时间内只有一个请求来构建缓存**（从数据库读取数据，再将数据更新到 Redis 里），当缓存构建完成后，再释放锁。未能获取互斥锁的请求，要么等待锁释放后重新读取缓存，要么就返回空值或者默认值。

3、**后台更新缓存**：业务线程不再负责更新缓存，缓存也不设置有效期，而是**让缓存“永久有效”，并将更新缓存的工作交由后台线程定时更新**。

 原因二：Redis 故障宕机。解决方式：

1、**服务熔断机制**：因为 Redis 故障宕机而导致缓存雪崩问题时，我们可以启动**服务熔断**机制，**暂停业务应用对缓存服务的访问，直接返回错误**，不用再继续访问数据库，从而降低对数据库的访问压力，保证数据库系统的正常运行，然后等到 Redis 恢复正常后，再允许业务应用访问缓存服务。服务熔断机制是保护数据库的正常允许，但是暂停了业务应用访问缓存服系统，全部业务都无法正常工作

2、**构建 Redis 缓存高可靠集群**：还可以通过**主从节点的方式构建 Redis 缓存高可靠集群**。如果 Redis 缓存的主节点故障宕机，从节点可以切换成为主节点，继续提供缓存服务，避免了由于 Redis 故障宕机而导致的缓存雪崩问题。

### 缓存击穿（类似于缓存雪崩的一个子集，数据量更小）

缓存中的**某个热点数据过期**了，此时大量的请求访问了该热点数据，就无法从缓存中读取，直接访问数据库，数据库很容易就被**高并发**的请求冲垮，这就是**缓存击穿**的问题。

### 缓存击穿的解决方法

**互斥锁方案（Redis 中使用 setNX 方法设置一个状态位，表示这是一种锁定状态），** 保证同一时间只有一个业务线程请求缓存，未能获取互斥锁的请求，要么等待锁释放后重新读取缓存，要么就返回空值或者默认值。

**不给热点数据设置过期时间**，由后台异步更新缓存，或者在热点数据准备要过期前，提前通知后台线程更新缓存以及重新设置过期时间；

### 缓存穿透

当用户访问的数据，**既不在缓存中，也不在数据库中**，导致请求在访问缓存时，发现缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据，没办法构建缓存数据，来服务后续的请求。那么当有大量这样的请求到来时，数据库的压力骤增，这就是**缓存穿透**的问题。

![image.png](Redis%20b578709820504e55b16b475594664497/image%2011.png)

### 缓存穿透的解决方案

**1、非法请求的限制**：当有大量恶意请求访问不存在的数据的时候，也会发生缓存穿透，因此**在 API 入口处我们要判断求请求参数是否合理，**请求参数是否含有非法值、请求字段是否存在，如果判断出是恶意请求就直接返回错误，避免进一步访问缓存和数据库。

**2、设置空值或者默认值**：当我们线上业务发现缓存穿透的现象时，可以针对查询的数据，**在缓存中设置一个空值或者默认值，** 这样后续请求就可以从缓存中读取到空值或者默认值，返回给应用，而不会继续查询数据库。

**追问：如果此时在数据库中新增了该空对象，也就是说此时他现在不在是一个空对象了，该怎么办？**

1 本来设置的方案就是先更新数据库，再删除缓存

2  兜底机制 设置过期时间30s

**3、使用布隆过滤器快速判断数据是否存在，避免通过查询数据库来判断数据是否存在**

---

### 布隆过滤器

布隆过滤器是一个非常神奇的数据结构，通过它我们可以非常方便地**判断一个给定数据是否存在于海量数据中。**

布隆过滤器由 **【初始值都为0的位图数组Bit Array】和【N个哈希函数】** 两部分组成。

- 当我们在写入数据库数据时，向布隆过滤器中添加元素，选定的哈希函数会被应用于这个元素，产生多个哈希值，每个哈希值对应位数组中的一个位置，然后这些位置上的值由0变成1，如果某一位置上原本已经是1，则不改变。
- 元素查询：使用所选定的哈希函数对这个元素进行哈希运算，检查数组中所有哈希值对应的位置，如果任意一个位置上的值为0，则可以确定这个元素不在布隆过滤器中。

相比于我们平时常用的 List、Map、Set 等数据结构，它 **占用空间更少** 并且效率更高，但是缺点是其返回的 **结果是概率性的，而不是非常准确的。** 理论情况下添加到集合中的元素越多，误报的可能性就越大。**（因为布隆过滤器是基于哈希函数实现查找的，高效查找的同时存在哈希冲突的可能性）** 并且，存放在布隆过滤器的数据不容易删除。

![image.png](Redis%20b578709820504e55b16b475594664497/image%2012.png)

Bloom Filter 会使用一个较大的 bit 数组来保存所有的数据，数组中的每个元素都只占用 1 bit ，并且每个元素只能是 0 或者 1（代表 false 或者 true），这也是 Bloom Filter 节省内存的核心所在。

把所有可能存在的请求的值都存放在布隆过滤器中，当用户请求过来，先判断用户发来的请求的值是否存在于布隆过滤器中。不存在的话，直接返回请求参数错误信息给客户端，存在的话才会走下面的流程。

### 有了解过其他类似的结构吗？

**Counting Bloom Filter(计数布隆过滤器)**

特点：在传统布隆过滤器的基础上，将二进制位数组替换为**计数器数组，每个计数器可以记录某个位置被多少个不同的哈希值设置过**。

应用场景：支持元素的删除操作，适用于需要动态添加和删除元素的场景。

**Quotient Filter（商过滤器）**

特点：通过将哈希值分成两部分，商（Quotient）和余数（Remainder）来进行存储，商用于确定元素在位数组中的位置，余数用于在该位置的桶中存储。

### 布隆过滤器与位图（BitMap）区别

1、存储数据：BitMap 需要为每一个可能的元素分配一个位（bit）、适用于**数据值范围较小且固定**的情况，如果数据值范围很大，BitMap的空间消耗会变得不可接受。布隆过滤器适合**元素范围大且对空间效率有较高要求的** 

2、误判率：BitMap是确定性的数据结构，没有误判率，布隆过滤器是存在误判率

3、删除操作：BitMap支持删除操作，只需将对应的位设为0。

## 4.2 如何设计一个缓存策略，可以动态的缓存热点数据?

由于数据存储受限，系统并不是将所有数据都需要存放到缓存中的，而**只是将其中一部分热点数据缓存起来。**
热点数据动态缓存的策略总体思路：**通过数据最新访问时间来做排名，并过滤掉不常访问的数据，只留下经常访问的数据**。

## 4.3 常见的缓存更新策略

常见的缓存更新策略：
**• Cache Aside（旁路缓存）策略；**

• Read/Write Through（读穿 / 写穿）策略；

• Write Back（写回）策略；

**实际开发中，MySQL和Redis用的最多的就是Cache Aside（旁路缓存策略）** Cache Aside（旁路缓存）策略是最常用的，应用程序直接与「数据库、缓存」交互，并负责对缓存的维护，该策略又可以细分为「读策略」和「写策略」。

![image.png](Redis%20b578709820504e55b16b475594664497/image%2013.png)

**因为缓存的写入通常要远远快于数据库的写入，所以无论是写策略还是读策略，都是要先对数据库进行操作，然后再对缓存进行操作。**

**Cache Aside 策略适合读多写少的场景，不适合写多的场景**，因为当写入比较频繁时，缓存中的数据会被频繁地清理，这样会对缓存的命中率有一些影响。

## 4.4 本地缓存和Redis缓存的区别

1、本地缓存：是指将数据**存储在本地应用程序或服务器上**，通常用于加速数据访问和提高响应速度。本地缓存通常使用内存作为存储介质，利用**内存的高速读写特性来提高访问速度**。

优：访问速度快、低延迟 缺：可拓展性有限

2、分布式缓存（Redis）：是指将数据**存储在多个分布式节点上**，通过协同工具来提供高性能的数据访问服务。

优：可拓展性强 缺：访问速度慢

# 5. Redis应用

Redis除了做缓存，还能做什么？

## 5.1 分布式锁（考过）

通常情况下，我们都是基于 Redisson 来实现分布式锁。

为了**保证共享资源被安全地访问**，我们需要使用**互斥操作**对共享资源进行保护，即同一时刻只允许一个线程访问共享资源，其他线程需要等待当前线程释放后才能访问。这样可以避免数据竞争和脏数据问题，保证程序的正确性和稳定性。

分布式系统下，不同的服务/客户端通常运行在独立的 JVM 进程上。如果多个 JVM 进程共享同一份资源的话，使用本地锁就没办法实现资源的互斥访问了。于是，**分布式锁** 就诞生了。

![image.png](Redis%20b578709820504e55b16b475594664497/image%2014.png)

**注：一个最基本的分布式锁需要满足：**

- **互斥**：任意一个时刻，锁只能被一个线程持有。
- **高可用**：锁服务是高可用的，当一个锁服务出现问题，能够自动切换到另外一个锁服务。并且，即使客户端的释放锁的代码逻辑出现问题，锁最终一定还是会被释放，不会影响其他线程对共享资源的访问。这一般是通过超时机制实现的。
- **可重入**：一个节点获取了锁之后，还可以再次获取锁。

### Redis做分布式锁可能存在问题？

- **锁超时问题：业务执行时间超过锁的过期时间，导致锁提前释放。**
- **锁误删问题：**

1、客户端A获取锁后处理时间过长，锁自动释放 

2、客户端B获取锁

3、客户端A完成操作后误删客户端B的锁。

使用Lua脚本保证检查值和删除的原子性

- **锁不可重入问题**

同一个线程在持有锁的情况下再次尝试获取锁会失败 → 导致死锁或业务逻辑无法执行。

---

**基于Redis实现分布式锁（看门狗机制）**

**基本原理：** 在 Redis 中， `SET NX` （Set if Not Exisits）命令是可以帮助我们实现互斥，如果 key 不存在的话，才会设置 key 的值。如果 key 已经存在， `SET NX` 啥也不做。

当线程要获取锁时，Redisson会尝试在Redis中设置一个唯一的锁标识（通常是一个UUID），如果该标识设置成功（锁未被占用），该线程就获得了锁；如果锁已经存在，线程则会等待或重试，直到获取了锁。
释放锁的话，为了防止误删到其他的锁，这里我们建议使用 **Lua 脚本通过 key 对应的 value（唯一值）来判断。**

选用 Lua 脚本是为了保证解锁操作的原子性。因为 Redis 在执行 Lua 脚本时，可以以原子性的方式执行，从而保证了锁释放操作的原子性。

---

## Redisson

Redisson 是一个基于 Redis 的 Java 客户端，不仅提供了对 Redis 基本操作的支持，还扩展了许多分布式功能，如分布式锁、分布式集合、分布式对象等。

Redisson的分布式锁，**解决了传统 Redis 的 SETNX 的缺陷：1、可重入锁：同一个线程可以重复获取锁。2、自动续期：防止业务执行时间过长导致锁过期（看门狗机制）。3、公平锁 & 非公平锁：支持按顺序获取锁。**

- **加锁机制**

![image.png](Redis%20b578709820504e55b16b475594664497/image%2015.png)

1、线程去获取锁，获取成功: 执行lua脚本，保存数据到redis数据库。

2、线程去获取锁，获取失败: 一直通过while循环尝试获取锁，获取成功后，执行lua脚本，保存数据到redis。

---

**lua脚本：**

具体使用RLock操作分布锁，RLock继承JDK的Lock接口，所以他有Lock接口的所有特性，比如lock、unlock、trylock等特性,同时它还有很多新特性：强制锁释放，带有效期的锁,。

---

- **看门狗机制**

Redisson的看门狗机制主要是为了解决**锁的自动过期**和**防止锁被意外释放**的问题。

1、看门狗功能：一旦线程获得锁，**Redisson会在后台启动一个看门狗线程，周期性地更新锁的过期时间。**（使得锁在执行任务期间不会被预设的过期时间释放）

2、过期时间的更新：看门狗会定期对Redis中的锁进行更新，**通常是每隔一段时间（例如，每500毫秒）向Redis发送一个命令，延续锁的有效期。**

3、看门狗的终止：当任务执行完成并正常释放锁时，Redisson会停止看门狗的线程，从而避免不必要的资源浪费。

---

![image.png](Redis%20b578709820504e55b16b475594664497/image%2016.png)

注：为了避免锁无法被释放，我们可以想到的解决办法就是：**给这个key设置一个过期时间。**

**Redisson 是一个开源的 Java 语言 Redis 客户端**，Redisson 中的分布式锁自带自动续期机制。保证锁不会因为超时而被释放。

在Redisson中，保存的状态（如分布式锁、集合数据、对象等）全部存储在Redis服务端。

## 5.2 **实现延迟队列**

延迟队列是指把当前要做的事情，往后推迟一段时间再做。延迟队列的常见使用场景有以下几种：

- 在淘宝、京东等购物平台上下单，超过一定时间未付款，订单会自动取消；
- 打车的时候，在规定时间没有车主接单，平台会取消你的单并提醒你暂时没有车主接单；
- 点外卖的时候，如果商家在10分钟还没接单，就会自动取消订单；

在 Redis 可以使用**有序集合（ZSet）** 的方式来实现延迟消息队列的，**ZSet 有一个 Score 属性可以用来存储延迟执行的时间。**

**使用 zadd score1 value1 命令就可以一直往内存中生产消息。**

**再利用 zrangebysocre 查询符合条件的所有待处理的任务， 通过循环执行队列任务即可。**

![Untitled](Redis%20b578709820504e55b16b475594664497/Untitled.png)

## 5.3 消息队列

**可以用Redis，但没必要**，**和专业的消息队列相比，还是有很多欠缺的地方。**

可以用List来实现，简易的消息队列

## 5.4 搜索引擎

Redis 是可以实现全文搜索引擎功能的，需要借助 **RediSearch** ，这是一个基于 Redis 的搜索引擎模块。**只适用于简单的小型项目的搜索场景。**

# 6.Redis线程

## 6.1 Redis是单线程还是多线程？

**Redis 单线程指的是「接收客户端请求->解析请求 ->进行数据读写等操作->发送数据给客户端」这个过程是由一个线程（主线程）来完成的**，这也是我们常说 Redis 是单线程的原因。

但是，**Redis程序并不是单线程的，Redis在启动的时候，是会启动后台线程（BIO）的。**

- **Redis 在 2.6 版本**，会启动 2 个后台线程，**分别处理关闭文件、AOF 刷盘**这两个任务。
- **Redis 在 4.0 版本之后**，新增了一个新的后台线程，用来异步释放 Redis 内存，也就是 lazyfree 线程。**例如执行 unlink key / flushdb async / flushall async 等命令，会把这些删除操作交给后台线程来执行，好处是不会导致 Redis 主线程卡顿。主要是针对一些大键值删除操作指令。**
- **Redis 在 6.0 版本之后**，采用了多个 I/O 线程来处理网络请求，**主要是为了提高网络IO的读写性能**这是因为随着网络硬件的性能提升，Redis 的性能瓶颈有时会出现在网络 I/O 的处理上。**但是对于命令的执行，Redis 仍然使用单线程来处理。Redis多线程只是在网络读写这类耗时操作上使用了，执行命令仍然是单线程顺序执行，无需担心线程安全问题。**

之所以 Redis 为「关闭文件、AOF 刷盘、释放内存」这些任务创建单独的线程来处理，是因为这些任务的操作都是很耗时的，如果把这些任务都放在主线程来处理，那么 Redis 主线程就很容易发生阻塞，这样就无法处理后续的请求了。

## 6.2 Redis中的I/O多路复用 → 单线程怎么监听大量的客户端连接？

Redis 通过 **IO 多路复用程序** **来监听来自客户端的大量连接（或者说是监听多个 socket）**，它会将感兴趣的事件及类型（读、写）注册到内核中并监听每个事件是否发生。

**I/O 多路复用技术的使用让 Redis 不需要额外创建多余的线程来监听客户端的大量连接，降低了资源的消耗（和 NIO 中的 `Selector` 组件很像）。**

![image.png](Redis%20b578709820504e55b16b475594664497/image%2017.png)

### Redis中I/O多路复用的工作流程

- **初始化阶段：** Redis服务器启动时，根据操作系统选择最佳的多路复用实现（select/poll/epoll）;创建事件循环（event loop）结构体。
- **事件注册：** 将监听套接字（sever socket）注册到多路复用机制中；关注读事件（客户端连接请求）
- **事件处理：** 读事件 → 接受新连接或读取客户端命令 写事件 → 将响应数据发送给客户端

“多路”指的是多个网络连接客户端，“复用”指的是复用同一个线程（单进程）。I/O 多路复用的其实是使用一个线程来检查多个 Socket 的就绪状态，在单个线程中通过记录跟踪每一个socket(I/O流) 的状态来管理处理多个 I/O 流。

**Redis单线程按顺序处理这些事件，但多路复用确保了所有请求都能被及时检测到。单线程处理多连接：1、虽然只有一个线程，但通过多路复用可以同时监控所有连接 2、当某个连接有数据到达时，Redis会立即处理。**

### Redis的网络模型？

Redis 6.0 版本之前，是用的**单Reactor单线程的模式**，到Redis 6.0 之后，就将网络IO的处理改成多线程的方式了。

## 6.3 Redis后台线程

实际还有一些后台线程用于执行一些比较耗时的操作：

- 通过 `bio_close_file` 后台线程来释放 AOF / RDB 等过程中产生的临时文件资源。
- 通过 `bio_aof_fsync` 后台线程调用 `fsync` 函数将系统内核缓冲区还未同步到到磁盘的数据强制刷到磁盘（ AOF 文件）。
- 通过 `bio_lazy_free`后台线程释放大对象（已删除）占用的内存空间。

---

在bio.h文件中有定义

```java
#ifndef __BIO_H
#define __BIO_H

/* Exported API */
void bioInit(void);
void bioCreateBackgroundJob(int type, void *arg1, void *arg2, void *arg3);
unsigned long long bioPendingJobsOfType(int type);
unsigned long long bioWaitStepOfType(int type);
time_t bioOlderJobOfType(int type);
void bioKillThreads(void);

/* Background job opcodes */
#define BIO_CLOSE_FILE    0 /* Deferred close(2) syscall. */
#define BIO_AOF_FSYNC     1 /* Deferred AOF fsync. */
#define BIO_LAZY_FREE     2 /* Deferred objects freeing. */
#define BIO_NUM_OPS       3

#endif
```

以上三个操作，都有其对应的任务队列

![image.png](Redis%20b578709820504e55b16b475594664497/image%2018.png)

## 6.4 为什么Redis采用单线程还这么快

1、Redis 的大部分操作**都在内存中完成**，并且采用了高效的数据结构。

2、Redis 采用单线程模型可以**避免了多线程之间的竞争，省去了多线程切换带来的时间和性能上的开销，**

**3、Redis 采用了 I/O 多路复用机制** 处理大量的客户端 Socket 请求。

# 7. Redis事务

**Redis 事务提供了一种将多个命令请求打包的功能。然后，再按顺序执行打包的所有命令，并且不会被中途打断类似于SQL中的事务**

在实际开发中这个东西并不常用。Redis事务和SQL这种关系型数据库中的事务并不相同。除了不满足原子性和持久性之外，事务中的每条命令都会与Redis服务器进行网络交互，这是一种比较浪费资源的行为。

**Redis 中并没有提供回滚机制**，虽然 Redis 提供了 DISCARD 命令，但是这个命令只能用来主动放弃事务执行，把暂存的命令队列清空，起不到回滚的效果。

## 7.1 ACID

**Redis 的事务和我们平时理解的关系型数据库的事务不同。**

1、Redis 事务在运行错误的情况下，除了执行过程中出现错误的命令外，其他命令都能正常执行。并且，Redis 事务是**不支持回滚（roll back）操作的。** 因此，Redis 事务其实是**不满足原子性的。**

2、Redis支持持久化（RDB快照、只追加文件AOF），但对事务来说，**持久性**也是无法保证的

## 7.2 一定要实现redis的原子性呢？

redis执行一条命令的时候是具备原子性的，因为redis执行命令的时候是单线程来处理的，不存在多线程安全的问题

但一定要保证2条命令的原子性的话，可以考虑使用 **Lua 脚本，将多个操作写到一个Lua 脚本中，Redis会把整个Lua脚本作为一个整体执行，在执行的过程中不会被其他命令打断，从而保证了Lua脚本操作的原子性。**

### Lua脚本保证原子性

**1、Redis中Lua脚本的原子性保证：单线程模型**：Redis使用单线程处理命令，Lua脚本执行期间不会穿插其他命令。**脚本完整执行**：整个脚本作为一个整体执行，要么全部执行成功，要么全部不执行。**无并发干扰**：脚本执行期间，不会有其他客户端命令被执行。

**2、通用Lua环境中的原子性保证：**

**使用锁机制**

```lua
-- 使用简单的互斥锁
local lock = {}

function atomicOperation()
    while lock[someResource] do
        -- 等待锁释放
    end
    lock[someResource] = true
    
    -- 执行原子操作
    
    lock[someResource] = false
end
```

# 8. Redis性能优化（重要）

## 使用批量操作减少网络传输

使用批量操作可以减少网络传输次数，进而减小网络开销 **（发送命令和返回结果，就是数据在网络上传输的时间）**

**1、原生批量操作指令：**

Redis 中有一些**原生支持批量操作**的命令，比如：`MGET`(获取一个或多个指定 key 的值)、`MSET`(设置一个或多个指定 key 的值)、`HMGET`(获取指定哈希表中一个或者多个指定字段的值)、`HMSET`(同时将一个或多个 field-value 对设置到指定哈希表中)、`SADD`（向指定集合添加一个或多个元素）

**2、pipeline**

对于不支持批量操作的命令，我们可以利用 **pipeline（流水线)** 将一批 Redis 命令封装成一组，这些 Redis 命令会被一次性提交到 Redis 服务器，只需要一次网络传输。

**3、Lua脚本**

Lua 脚本同样支持批量操作多条命令。一段 Lua 脚本可以视作一条命令执行，可以看作是**原子操作**。也就是说，**一段 Lua 脚本执行过程中不会有其他脚本或 Redis 命令同时执行，保证了操作不会被其他指令插入或打扰，** 这是 pipeline 所不具备的。

## 解决大量key集中过期问题

1、给key设置随机过期时间

2、开启lazy-free(惰性删除/延迟释放)

## 解决big key问题

如果一个 key 对应的 value 所占用的内存比较大，那这个 key 就可以看作是 big key。

## 解决hot key（热key）问题  （考过！）

如果一个 key 的**访问次数比较多且明显多于其他 key** 的话，那这个 key 就可以看作是 **hotkey（热 Key）**。hotkey 出现的原因主要是某个热点数据访问量暴增，如重大的热搜事件、参与秒杀的商品。

### hotkey的危害

1、处理 hotkey 会**占用大量的 CPU 和带宽**，可能**会影响 Redis 实例对其他请求的正常处理。**

2、如果突然访问 hotkey 的请求超出了 Redis 的处理能力，Redis 就会直接宕机。这种情况下，大量请求将落到后面的数据库上，可能会导致数据库崩溃。

### 解决hotkey

- **读写分离   通过主从复制，主节点处理写请求，从节点处理读请求。**
- **数据分片（Sharding）** 将热点key分散 **（通过哈希算法）** 到多个key中，减轻单个key的压力。
- **本地缓存**  在应用服务器本地缓存热点key的数据，减少对Redis的访问。使用本地缓存（如Guava Cache、Caffeine）缓存热点key。
- **二级缓存：（缓存的缓存）** hotkey 采用二级缓存的方式进行处理，在**应用层增加二级缓存，优先从二级缓存读取数据。**

 ****

# 10.常用的缓存读写策略 （数据库和缓存如何保证一致性？，这个真得好好看看）

对缓存的操作，无非就是两种：更新/删除

方法一：先更新库，再更新缓存：会存在不一致问题。

![屏幕截图 2025-03-10 212241.png](Redis%20b578709820504e55b16b475594664497/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE_2025-03-10_212241.png)

方法二：先更新缓存，再更新库，还是会存在不一致问题。

![image.png](Redis%20b578709820504e55b16b475594664497/image%2019.png)

方法三、先删除缓存，再更新库

读写并发情况下：（左边读，右边写）

![屏幕截图 2025-03-10 212845.png](Redis%20b578709820504e55b16b475594664497/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE_2025-03-10_212845.png)

方法四、先更新库，再删除缓存

![屏幕截图 2025-03-10 213001.png](Redis%20b578709820504e55b16b475594664497/%E5%B1%8F%E5%B9%95%E6%88%AA%E5%9B%BE_2025-03-10_213001.png)

这种情况发送的概率非常小，修改数据库的时间间隔大概率大于读取数据库的时间间隔。

## 10.1 **Cache Aside Pattern 旁路缓存模式**

**适合读请求比较多的场景。** Cache Aside Pattern 中服务端需要同时维系 db 和 cache，并且是以 db 的结果为准。

**写：先更新db,再直接删除cache。**

![image.png](Redis%20b578709820504e55b16b475594664497/image%2020.png)

读：从 cache 中读取数据，读取到就直接返回   

cache 中读取不到的话，就从 db 中读取数据返回

再把数据放到 cache 中

![image.png](Redis%20b578709820504e55b16b475594664497/image%2021.png)

注：在写数据的过程中，先删除cache，后更新db是不可以的 ！会造成db和cache数据不一致。先更新dp，后删除cahce是可以的。理论上也会存在数据不一致的问题，但概率非常小，因为缓存的写入速度比数据库写入速度要快许多。

## 10.2 Read/Write Through Pattern读写穿透

Read/Write Through Pattern 中服务端把 **cache 视为主要数据存储**，从中读取数据并将数据写入其中。cache 服务负责将此数据读取和写入 db，从而减轻了应用程序的职责。

**写（Write Through）：**

先查 cache，cache 中不存在，直接更新 db。

**cache 中存在，则先更新 cache，然后 cache 服务自己更新 db（同步更新 cache 和 db）。**

![image.png](Redis%20b578709820504e55b16b475594664497/image%2022.png)

**读(Read Through)：** 从 cache 中读取数据，读取到就直接返回 。

读取不到的话，先从 db 加载，写入到 cache 后返回响应。

![image.png](Redis%20b578709820504e55b16b475594664497/image%2023.png)

## 10.3 Write Behind Pattern 异步缓存写入

Write Behind Pattern 和 Read/Write Through Pattern 很相似，两者都是由 cache 服务来负责 cache 和 db 的读写。非常非常少见！！！

但是，两个又有很大的不同：**Read/Write Through 是同步更新 cache 和 db，而 Write Behind 则是只更新缓存，不直接更新 db，而是改为异步批量的方式来更新 db。**

### 多级缓存如何保证数据一致性

---

方案一、通过**redis的过期时间来更新缓存**，mysql 数据库更新不会触发redis 更新，**只有当redis的key过期后才会重新加载**

缺点：
• 数据不一致的时间较长，会造成一定的脏数据

• 完全依赖过去时间，过期时间太短缓存更新太频繁，过长容易有太长时间更新延迟。

---

方案二、让key 的过期时间做兜底，在更新mysql 的同时也会更新redis.

**缺点**：如果更新mysql 成功，更新redis 失败，又会成为方案一。

---

方案三、对redis 的更新操作进行优化，增加消息队列，转为异步更新redis 数据， 将redis 的更新操作交给MQ ，队列来保证可靠性，异步更新redis。

**缺点**：

- 解决不了时序的问题，如果有多个业务实例对同一条数据进行更新，数据更新的先后顺序可能会乱。
- 引入mq ,增加的系统复杂性，增加mq的维护成本。

---

方案四、将mysql和redis更新放在一个事务中操作，这样能保证达到强一致性。

**缺点：**

- mysql或者redis任何一个环节出问题，都会造成数据回滚或者撤销。
- 如果网络出现超时，不仅可能会造成数据回滚或者撤销，还会有并发问题。

方案五、通过订阅mysql的Binlog 日志来更新redis, 把我们搭建的mq消费服务，作为mysql的一个salve ，订阅Binlog ，解析出更新的内容，再更新redis

**缺点**：要单独搭建一个同步服务，并且来引入BinLog同步机制，成本较大。

---

### 针对旁路缓存模式的一些问题？（这个好好看看）

- 问题一：「**先更新数据库，再删缓存**」的策略其实是两个操作，**在删除缓存（第二个操作）的时候失败了，导致缓存中的数据是旧值，而数据库是最新值**。**如何保证「先更新数据库 ，再删除缓存」这两个操作能执行成功？**

解决一、消息队列，**异步重试**：将删除缓存的任务放入消息队列（如 RabbitMQ、Kafka 等），由消费者异步重试，直到成功为止。

我们可以引入**消息队列**，将第二个操作（删除缓存）要操作的数据加入到消息队列，由消费者来操作数据。

解决二、重试机制。如果应用**删除缓存失败**，可以从消息队列中重新读取数据，然后再次删除缓存，这个就是**重试机制**。

当然，如果重试超过的一定次数，还是没有成功，我们就需要向业务层发送报错信息了。

![image.png](Redis%20b578709820504e55b16b475594664497/image%2024.png)

 解决三、**监听数据库变更：订阅 MySQL binlog，再操作缓存**

「**先更新数据库，再删缓存**」的策略的第一步是更新数据库，那么更新数据库成功，就会产生一条变更日志，记录在 binlog 里。
**将binlog日志采集发送到MQ队列里面，然后编写一个简单的缓存删除消息者订阅binlog日志，根据更新log删除缓存，并且通过ACK机制确认处理这条更新log，保证数据缓存一致性。**

这些方法有一个共同的特点，都是采用**异步操作缓存**。

- 问题二：**如果在读写操作中，依然发送数据不一致（就按上图所示的那样，更新缓存发生在删除缓存之后，虽然这是小概率事件）怎么解决？**

![屏幕截图 2025-03-10 213001.png](Redis%20b578709820504e55b16b475594664497/e7d1f743-3e6e-4674-8c69-bc135bd75a34.png)

解决方法一、和上面问题解决方案类似，消息队列实现 **【延迟双删】** 策略：在「先更新数据库，再删除缓存」的基础上，**增加一个延迟删除操作，** 确保读线程的缓存更新不会覆盖写线程的最新数据。

解决方案二、**消息队列 + 顺序消费：** 通过消息队列保证写操作的顺序性，**确保缓存删除操作在缓存更新操作之前执行。**

# 11. Redis 内存碎片

内存碎片可简单的理解为那些不可用的空间

## 11.1 Redis内存碎片的产生原因

**1、Redis 存储数据的时候向操作系统申请的内存空间可能会大于数据实际需要的存储空间。**

**2、频繁修改 Redis 中的数据也会产生内存碎片。**

3、不同大小的键值对：如果存储的键值对大小差异较大，容易产生内存碎片。

## 11.2 查看Redis内存碎片信息

使用 `info memory` 命令即可查看 Redis 内存相关的信息。

## 11.3 解决内存碎片的方法

- **启用内存碎片整理：** Redis 4.0 及以上版本支持内存碎片整理功能（Active Defragmentation），可以动态整理内存碎片。

Redis4.0-RC3 版本以后自带了内存整理，可以避免内存碎片率过大的问题。直接通过 `config set` 命令将 `activedefrag` 配置项设置为 `yes` 即可。

- **优化内存分配器：** Redis 默认使用 jemalloc 内存分配器，可以通过优化分配器参数减少内存碎片。
- **优化数据存储：** 通过优化数据存储方式，可以减少内存碎片：

使用较小的键值对：避免存储过大的键值对。

使用哈希表或列表：将多个小对象存储在一个哈希表或列表中，减少内存分配次数。

使用压缩：对于较大的值，可以使用 Redis 的压缩功能（如 ziplist 或 quicklist）。

# 12 Redis常见阻塞的原因

**1、O（n）命令**

**2、SAVE创建RDB快照**

3、AOF日志记录阻塞、刷盘阻塞、重写阻塞

**4、大Key操作：查找大Key、删除大Key**

**5、Swap内存交换**

# 13. Redis 集群

一定要从 Redis 的多服务节点来考虑，比如 Redis 的主从复制、哨兵模式、切片集群。（实现高可用）**redis主从和集群在CAP理论都属于AP模型**，即在面临网络分区时选择保证可用性和分区容忍性，而牺牲了强一致性。这意味着在网络分区的情况下，Redis主从复制和集群可以继续提供服务并保持可用，但可能会出现部分节点间的数据不一致。

## Redis 主从同步中的增量和完全同步怎么实现？

### 1、完全同步

完全同步发生：

**1、初次同步：** 当一个服务器（slave）首次连接到主服务器（master）时，会进行一次完全同步。

**2、从服务器数据丢失**：如果从服务器数据由于某种原因（如断电）丢失，它会请求进行完全同步。

**3、主服务器数据发生变化：** 如果从服务器长时间未与主服务器同步，**导致数据差异太大**，也可以触发完全同步。

**主从服务器间的第一次同步的过程可以分为三个阶段：**

**第一阶段是建立连接，协商同步；**

**第二阶段是主服务器同步数据给从服务器；**

**第三阶段是主服务器发送新写操作命令给从服务器；**

![image.png](Redis%20b578709820504e55b16b475594664497/image%2025.png)

传递的过程主要是RDB文件的形式来传递的。

### 2、增量同步

增量同步是指**从节点已经与主节点保持了一定程度的数据一致性后**，主节点将新的写操作实时发送给从节点，以保持数据的持续同步。

增量同步允许从服务器**从断点处继续同步，而不是每次都进行完全同步**。它基于 PSYNC命令，使用允许ID（run ID）和复制偏移量（offset）的概念。

![image.png](Redis%20b578709820504e55b16b475594664497/image%2026.png)

主要步骤：

1、从服务器在恢复网络后，会发送 psync 命令给主服务器，此时的psync命令里的offset参数不是-1；

2、主服务器收到该命令后，然后用CONTINUE响应命令告诉从服务器接下来采用增量复制的方式同步数据；

3、然后主服务将**主从服务器断线期间，所执行的写命令发送给从服务器，然后从服务器执行这些命令；**

---

repl_backlog_buffer : [环型]缓冲区，用于主从服务器断连后，从中找到差异的数据

![image.png](Redis%20b578709820504e55b16b475594664497/image%2027.png)

如果判断出从服务器要读取的数据**还在repl_backlog_buffer缓冲区里，** 那么主服务器将采用**增量同步**的方式。

相反，如果判断出从服务器要读取的数据已经**不存在repl_backlog_buffer缓冲区里**，那么主服务器将采用**全量同步**的方式 **（不在缓冲区里，说明数据差异过大）**

为了避免在网络恢复时，主服务器频繁的使用全量同步的方式，我们应该调整下repl_backlog_buffer缓冲区大小，尽可能的大一些。

---

## 13.1 主从复制

主从复制是 Redis 高可用服务的最基础的保证，实现方案就是将从前的一台 Redis 服务器，同步数据到多台从 Redis 服务器上，即一主多从的模式，且主从服务器之间采用的是「读写分离」的方式。

![image.png](Redis%20b578709820504e55b16b475594664497/image%2028.png)

所有的数据修改**只在主服务器上进行，** 然后 **将最新的数据同步给从服务器，** 主从服务器之间的命令复制是**异步**进行的。（无法保证强一致性，数据间的不一致是不可避免的）

## 13.2 哨兵模式

当 Redis 的主从服务器出现故障宕机时，Redis 增加了哨兵模式（**Redis Sentinel**），因为哨兵模式做到了可以监控主从服务器，并且提供**主从节点故障转移的功能。**

![image.png](Redis%20b578709820504e55b16b475594664497/image%2029.png)

哨兵节点主要负责三件事：**监控、选主、通知**

典型的哨兵部署包含以下组件：1个主节点、N个从节点、M个哨兵节点**（通常为奇数个，组成哨兵集群）**

### 客观下线模式

当某个哨兵节点认为主节点不可用时，**会向其他哨兵发送 SENTINEL is-master-down-by-addr 命令询问。**如果**超过半数哨兵（由quorum参数控制）确认主节点不可达**，则主节点被标记为客观下线，触发故障转移。

### 故障转移

使用Raft算法选举一个哨兵作为领导者（Leader），由它负责执行故障转移。选举条件：获得多数哨兵的投票（如3个哨兵需至少2票）。

## 13.3 切片集群（重要！！！）

当 Redis 缓存数据量大到一台服务器无法缓存时，就需要使用 **Redis 切片集群（Redis Cluster ）** 方案。**它将数据分布在不同的服务器上**，以此来**降低系统对单主节点的依赖，** 从而**提高 Redis 服务的读写性能。**

**Redis Cluster 方案采用哈希槽（Hash Slot），来处理数据和节点之间的映射关系。** 在 Redis Cluster 方案中，**一个切片集群共有 16384 个哈希槽**，这些哈希槽类似于数据分区，每个键值对都会根据它的 key，被映射到一个哈希槽中，具体执行过程分为两大步：

step1、根据键值对的 key，按照 [**CRC16 算法 (opens new window)**](https://en.wikipedia.org/wiki/Cyclic_redundancy_check)计算一个 16 bit 的值。

step2、再用 16bit 值对 16384 取模，得到 0~16383 范围内的模数，每个模数代表一个相应编号的哈希槽。

### 哈希槽怎么被映射到具体的 Redis 节点上的呢？

**平均分配：** 在使用 cluster create 命令创建 Redis 集群时，Redis会自动把所有**哈希槽平均分布到**集群节点上。比如集群中有 9 个节点，则每个节点上槽的个数为 16384/9 个。

**手动分配：** 可以使用 cluster meet 命令手动建立节点间的连接，组成集群，再使用 cluster addslots 命令，指定每个节点上的哈希槽个数。

![image.png](Redis%20b578709820504e55b16b475594664497/image%2030.png)

在手动分配哈希槽时，需要把 16384 个槽都分配完，否则 Redis 集群无法正常工作。

### Redis集群模式优点\缺点

优点：高可用、高性能、扩展性好

缺点：部署和维护比较复杂、集群同步问题（当某些节点失败或者网络出现故障，集群中数据同步的问题也会出现）

## 13.4 脑裂问题

在 Redis 主从架构中，部署方式一般是「一主多从」，主节点提供写操作，从节点提供读操作。

哨兵发现主节点失联了，它就认为主节点挂了（但实际上主节点正常运行，只是网络出问题了），于是哨兵就会在「从节点」中选举出一个 leader 作为主节点，这时集群就有两个主节点了  —— **脑裂出现了**。
等网络恢复，**旧主节点会降级为从节点，** 再与新主节点进行同步复制的时候，由于会**从节点会清空自己的缓冲区，所以导致之前客户端写入的数据丢失了。**

### 解决方案

当主节点发现从节点下线或者通信超时的总数量**小于阈值时**，那么 **禁止主节点进行写数据，** 直接把错误返回给客户端。（阈值：主库连接的从库中至少有 N 个从库，和主库进行数据复制时的 ACK 消息延迟不能超过 T 秒）

**等到新主库上线时，就只有新主库能接收和处理客户端请求，此时，新写的数据会被直接写到新主库中。而原主库会被哨兵降为从库，即使它的数据被清空了，也不会有新数据丢失。**

# 14. Redis过期删除与内存淘汰

### 过期删除策略和内存淘汰策略有什么区别？

1、**内存淘汰策略是在内存满了的时候，redis会触发内存淘汰策略，** 来淘汰一些不必要的内存资源，以腾出空间，来保存新的内容。

2、Redis 是可以对 key 设置过期时间的，因此需要有相应的机制将**已过期的键值对删除**，而做这个工作的就是**过期键值删除策略。** 每当我们对一个 key 设置了过期时间时，Redis 会把该 key 带上过期时间存储到一个**过期字典**（expires dict）中，也就是说「过期字典」保存了数据库中所有 key 的过期时间。Redis 使用的过期删除策略是 **「惰性删除+定期删除」** 这两种策略配和使用。

## 惰性删除策略

**不主动删除过期键，每次从数据库访问 key 时，都检测 key 是否过期，如果过期则删除该 key。**

![image.png](Redis%20b578709820504e55b16b475594664497/image%2031.png)

惰性删除策略对 CPU 时间最友好。

如果一个 key 已经过期，而这个 key 又仍然保留在数据库中，那么只要这个过期 key 一直没有被访问，它所占用的内存就不会释放。

## 定期删除策略

**每隔一段时间「随机」从数据库中取出一定数量的 key 进行检查（这也是由后台线程完成的），并删除其中的过期key。**

Redis 的定期删除的流程：

1. 从过期字典中随机抽取 20 个 key；

2. 检查这 20 个 key 是否过期，并删除已过期的 key；

3. 如果本轮检查的已过期 key 的数量，超过 5 个（20/4），也就是「已过期 key 的数量」占比「随机抽取 key 的数量」大于 25%，则继续重复步骤 1；如果已过期的 key 比例小于 25%，则停止继续删除过期 key，然后等待下一轮再检查。

![image.png](Redis%20b578709820504e55b16b475594664497/image%2032.png)

---

**优点:  通过限制删除操作执行的时长和频率，来减少删除操作对 CPU 的影响，同时也能删除一部分过期的数据减少了过期键对空间的无效占用。**

**缺点:  难以确定删除操作执行的时长和频率。如果执行的太频繁，就会对 CPU 不友好；** 如果执行的太少，那又和惰性删除一样了，过期 key 占用的内存不会及时得到释放。

---

### **Redis 持久化时，对过期键会如何处理的？**

**RDB 文件生成阶段**：从内存状态持久化成 RDB（文件）的时候，会对 key 进行过期检查，**过期的键「不会」被保存到新的 RDB 文件中。**

**RDB 加载阶段**：RDB 加载阶段时，要看服务器是主服务器还是从服务器，**程序会对文件中保存的键进行检查，过期键「不会」被载入到数据库中**。**如果 Redis 是「从服务器」运行模式的话，在载入 RDB 文件时，不论键是否过期都会被载入到数据库中**。

AOF 文件分为两个阶段，AOF 文件写入阶段和 AOF 重写阶段。

**AOF 文件写入阶段**：当 Redis 以 AOF 模式持久化时，**如果数据库某个过期键还没被删除，那么 AOF 文件会保留此过期键，当此过期键被删除后，Redis 会向 AOF 文件追加一条 DEL 命令来显式地删除该键值**。

**AOF 重写阶段**：执行 AOF 重写时，会对 Redis 中的键值对进行检查，**已过期的键不会被保存到重写后的 AOF 文件中**，因此不会对AOF 重写造成任何影响。

---

## 内存淘汰机制（Redis内存满了会怎样，一共8种）

在 Redis 的 **运行内存达到了某个阀值，** 就会触发 **内存淘汰机制，这个阀值就是我们设置的最大运行内存，此值在 Redis 的配置文件中可以找到，配置项为 maxmemory。**

***1、不进行数据淘汰的策略***

**noeviction**（Redis3.0之后，默认的内存淘汰策略） 它表示当运行内存超过最大设置内存时，不淘汰任何数据，而是不再提供服务，直接返回错误。

***2、进行数据淘汰的策略***

**1、在设置了过期时间的数据中进行淘汰**
**volatile-random**：随机淘汰设置了过期时间的任意键值；

**volatile-ttl**：优先淘汰更早过期的键值。

**volatile-lru**（Redis3.0 之前，默认的内存淘汰策略）：淘汰所有设置了过期时间的键值中，**最久未使用的键值；**

**volatile-lfu**（Redis 4.0 后新增的内存淘汰策略）：淘汰所有设置了过期时间的键值中，**最少使用的键值；**

**2、在所有数据范围内进行淘汰**

**allkeys-random:** 随机淘汰任意键值;

**allkeys-lru:** 淘汰整个键值中最久未使用的键值；

**allkeys-lfu**（Redis 4.0 后新增的内存淘汰策略): 淘汰整个键值中最少使用的键值。

---

注：1> LFU Least Frequently Used 最不经常使用   2> LRU Least Recently Used 最近最少使用

### LRU、LFU的缺点？

**LRU 最近最少使用** 

1、新写入的key会立即进入“最近使用”状态，可能会导致真正的热点数据被新写入的冷数据挤出。

2、对于周期性访问但时间间隔较长的数据不友好。

**LFU 最不经常使用**

1、新写入的key计数为0，容易立即被淘汰。

2、突然变热的数据需要时间累积足够的访问计数。

### 为什么不过期立即删除？

在过期key比较多的情况下，删除过期key可能会占用相当一部分CPU时间，在内存不紧张但CPU时间紧张的情况下，将CPU时间用于删除和当前任务无关的过期键上，**无疑会对服务器的响应时间和吞吐量造成影响。所以，定期删除策略对CPU不友好。**

# 15.其他问题

## 15.1 Redis支持模糊查询吗？

Redis **本身并不支持传统意义上的模糊查询**（特别是关系型数据库中的那种 SQL 语法），但可以通过一些方式实现类似的功能。这里是几种常见的实现模糊查询的方式：

**1、使用通配符：** 如果使用的是 Redis 的键空间（keyspace）功能，可以使用通配符 (`*`) 进行键的匹配。

```sql
KEYS user:*      # 匹配所有以 'user:' 开头的键
```

2、使用数据结构

**Redis Sets**：可以将相关的值存储在集合中，然后使用集合的操作来实现模糊匹配。

**Redis Sorted Sets**：可以对值进行排序和评分，可以用来实现范围查询。

**哈希表（Hashes）**：可以将多个字段存储在一个哈希表中，可以通过键值对来实现某些模糊查询。

3、使用Redis Search

如果需要更复杂的模糊查询（如全文搜索），可以考虑使用 RedisSearch

## 15.2 Redis缓存时间如何设置？

通过简单命令设置缓存的过期时间

**1、使用`EXPIRE` 命令**

```sql
EXPIRE key seconds
EXPIRE mykey 60 #将键mykey的过期时间设置为 60 秒
```

**2、使用 `SET` 命令的选项**

```sql
SET mykey value EX 60 #当你使用 SET 命令设置值时，可以直接指定过期时间。这将把 mykey 设置为 value，并在 60 秒后过期。
```

**3、使用 `SETEX` 命令**

`SETEX` 是一个直接设置值并指定过期时间的命令。

```sql
SETEX mykey 60 value
```

## 15.3 Redis过期key的处理方法？

1、惰性删除  

2、定期删除

**3、内存回收：**

当Redis的内存使用量到达上限时，Redis会触发内存回收机制，在回收内存时，Redis会优先删除过期的键，具体来说，Redis会使用以下策略：**LRU、LFU。**

## 15.4 Redis定时任务的时间如何设置？

1、使用EXPIRE和惰性删除（前面提到了）

2、使用Sorted Set实现延时队列（前面也提到了）

**3、使用Lua脚本实现定时任务**可以使用Lua脚本，定时执行一些任务，Redis的Lua脚本可以直接在服务端执行，避免网络延迟，提高了执行效率

## 15.5 Redis怎么保证原子性？

1、**单线程模型**：Redis使用单线程处理命令，避免了多线程竞争问题，所有命令按顺序执行，保证了每个操作的原子性

2、事务（MULTI/EXEC）:事务块：通过MULTI和EXEC命令将多个操作打包成一个事务，确保这些操作要么全部执行，要么全部不执行。

3、原子操作指令：Redis提供了许多原子操作命令，如INCR、DECR、SETNX等，这些命令在执行时不会被中断。

## 15.6 如何保证Redis中长期保留热点数据（2000w数据，Redis只存20w,如何精准抓住热点）

**Step1、Redis层做一个优化配置**，根据现实场景配置淘汰策略。

稳定热点（商品详情）—> LFU 淘汰访问频率最低；限时活动（秒杀）—> TTL 淘汰剩余时间最短。

**Step2、考虑实时热点的变化：实时热点探测**

借助一些中间件，比如 **Flink** ，去处理Top前20w的数据。

**Step3、多级缓存架构（防御矩阵）** 

![image.png](Redis%20b578709820504e55b16b475594664497/image%2033.png)

先查本地缓存，再查Redis缓存

其中，还要考虑一些优化：

1、**缓存雪崩保护**（随机设置过期时间，避免集体失效）

2、**热点key分片** 

3、多级缓存降级策略

![image.png](Redis%20b578709820504e55b16b475594664497/85f08d90-f64c-4389-ad1a-891c6cbbf71f.png)

### 如何保留热点数据？

**1、调整内存淘汰策略：volatile-lfu 或 allkeys-lfu 优先淘汰最不频繁使用（LFU）的数据。**

**2、分离热点数据与普通数据，** 通过多实例或多数据库隔离数据，精细化控制；

**3、取消热点数据的过期时间：** 1）不设置TTL 2）动态续期：每次访问热点数据时，通过EXPIRE或PEXPTRE重置过期时间，模拟“长期保留”的效果。

## 15.7 Redis有哪些缺点？

- **内存依赖 ：** 所有数据**必须存储在内存中**，单实例数据量受物理内存限制（即使使用虚拟内存功能，性能也会大幅下降）。无法存储超大规模数据。

解决方案：

**1、分片扩展：** 使用 Redis Cluster 将数据分散到多个节点。

**2、冷热分离：** 将冷数据归档到磁盘数据库（如 MySQL），仅保留热数据在 Redis。

- **弱事务支持：** 事务仅支持命令批量执行（MULTI/EXEC），**不支持回滚（Rollback）。**

解决方案：**Lua 脚本：** 通过原子性脚本实现复杂逻辑

- **查询能力有限：缺乏关联查询、聚合计算等复杂操作**（如 SQL 中的 JOIN 或 GROUP BY）。
